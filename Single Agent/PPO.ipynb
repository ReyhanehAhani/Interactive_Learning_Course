{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KFX5FBGOJkig"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gym\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import numpy as np\n",
        "from stable_baselines3 import DQN, PPO, A2C\n",
        "import pygame\n",
        "import threading\n",
        "import time\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import pygame\n",
        "import gym\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import numpy as np\n",
        "from stable_baselines3 import DQN, PPO, A2C\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class PongEnvironment(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(PongEnvironment, self).__init__()\n",
        "        self.width = 400\n",
        "        self.height = 300\n",
        "        self.ball_radius = 10\n",
        "        self.paddle_width = 10\n",
        "        self.paddle_height = 60\n",
        "        self.paddle_offset = 20\n",
        "        self.ball_pos = np.array([self.width // 2, self.height // 2], dtype=float)\n",
        "        self.ball_vel = np.array([5, 1], dtype=float) * 100\n",
        "        self.paddle_pos = self.height // 2\n",
        "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
        "        pygame.display.set_caption(\"Pong\")\n",
        "\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.time_step=0\n",
        "        self.start_time=time.time()\n",
        "        self.tot_reward=0\n",
        "        self.ball_pos = np.array([self.width // 2, self.height // random.randrange(1,10)], dtype=float)\n",
        "        self.ball_vel = np.array([random.random(), random.random()], dtype=float) * 100\n",
        "        self.paddle_pos = self.height // 2\n",
        "        return self.get_state()\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        self.time_step+=1\n",
        "        if action == 0:\n",
        "            move = -5\n",
        "        else:\n",
        "            move = 5\n",
        "        self.move_paddle(move)\n",
        "        self.ball_pos += self.ball_vel\n",
        "\n",
        "        if (\n",
        "            self.ball_pos[1] <= self.ball_radius\n",
        "            or self.ball_pos[1] >= self.height - self.ball_radius\n",
        "        ):\n",
        "            self.ball_vel[1] *= -1\n",
        "\n",
        "        reward = 0\n",
        "        done = False\n",
        "\n",
        "        if self.ball_pos[0] <= self.paddle_width + self.ball_radius:\n",
        "            if (\n",
        "                self.paddle_pos - self.paddle_height / 2\n",
        "                <= self.ball_pos[1]\n",
        "                <= self.paddle_pos + self.paddle_height / 2\n",
        "            ):\n",
        "                self.ball_vel[0] *= -1\n",
        "                reward = 1\n",
        "                self.tot_reward+=1\n",
        "            else:\n",
        "                reward = 0\n",
        "                done = True\n",
        "        if self.tot_reward>10 or time.time()-self.start_time>30:\n",
        "                print('xxx')\n",
        "                done = True\n",
        "        if self.ball_pos[0] >= self.width - self.ball_radius - self.paddle_width:\n",
        "            self.ball_vel[0] *= -1\n",
        "\n",
        "        return self.get_state(), reward, done, {}\n",
        "\n",
        "    def move_paddle(self, move):\n",
        "        self.paddle_pos = np.clip(\n",
        "            self.paddle_pos + move,\n",
        "            self.paddle_height / 2,\n",
        "            self.height - self.paddle_height / 2,\n",
        "        )\n",
        "\n",
        "    def get_state(self):\n",
        "        return np.array(\n",
        "            [\n",
        "                self.ball_pos[0] / self.width,\n",
        "                self.ball_pos[1] / self.height,\n",
        "                self.ball_vel[0] / 100,\n",
        "                self.ball_vel[1] / 100,\n",
        "                self.paddle_pos / self.height,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def render(self, mode=\"rgb_array\"):\n",
        "        self.screen.fill((0, 0, 0))\n",
        "        pygame.draw.rect(\n",
        "            self.screen,\n",
        "            (255, 255, 255),\n",
        "            pygame.Rect(\n",
        "                0,\n",
        "                int(self.paddle_pos - self.paddle_height / 2),\n",
        "                self.paddle_width,\n",
        "                self.paddle_height,\n",
        "            ),\n",
        "        )\n",
        "        pygame.draw.circle(\n",
        "            self.screen,\n",
        "            (255, 255, 255),\n",
        "            (int(self.ball_pos[0]), int(self.ball_pos[1])),\n",
        "            self.ball_radius,\n",
        "        )\n",
        "        pygame.display.update()\n",
        "\n",
        "        if mode == \"rgb_array\":\n",
        "            data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
        "            return np.transpose(data, (1, 0, 2))\n",
        "        return np.transpose(data, (1, 0, 2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x-80PVzJkih",
        "outputId": "5d7bbfa8-728d-43d4-9ab5-b398aa4b3f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.99     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 8871     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 102      |\n",
            "----------------------------------\n",
            "xxx\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.972    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 7119     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 294      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.969    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 6536     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 330      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.961    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 6387     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 408      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.955    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 6194     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 477      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.949    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 6040     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 541      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.92     |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 6547     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 843      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.913    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 6464     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 914      |\n",
            "----------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    total_timesteps  | 86399    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.57e-05 |\n",
            "|    n_updates        | 9099     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 924      |\n",
            "|    fps              | 1861     |\n",
            "|    time_elapsed     | 46       |\n",
            "|    total_timesteps  | 86470    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00842  |\n",
            "|    n_updates        | 9117     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 928      |\n",
            "|    fps              | 1852     |\n",
            "|    time_elapsed     | 46       |\n",
            "|    total_timesteps  | 86887    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 9221     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 932      |\n",
            "|    fps              | 1848     |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 87055    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000459 |\n",
            "|    n_updates        | 9263     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 936      |\n",
            "|    fps              | 1847     |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 87097    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000244 |\n",
            "|    n_updates        | 9274     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 940      |\n",
            "|    fps              | 1836     |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 87598    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.32e-05 |\n",
            "|    n_updates        | 9399     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 944      |\n",
            "|    fps              | 1831     |\n",
            "|    time_elapsed     | 47       |\n",
            "|    total_timesteps  | 87838    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.26e-05 |\n",
            "|    n_updates        | 9459     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 948      |\n",
            "|    fps              | 1829     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 87907    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00108  |\n",
            "|    n_updates        | 9476     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 952      |\n",
            "|    fps              | 1825     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 88113    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.4e-05  |\n",
            "|    n_updates        | 9528     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 956      |\n",
            "|    fps              | 1822     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 88272    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.16e-05 |\n",
            "|    n_updates        | 9567     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 960      |\n",
            "|    fps              | 1821     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 88329    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.32e-05 |\n",
            "|    n_updates        | 9582     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 964      |\n",
            "|    fps              | 1817     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 88521    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00824  |\n",
            "|    n_updates        | 9630     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 968      |\n",
            "|    fps              | 1816     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 88557    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.49e-05 |\n",
            "|    n_updates        | 9639     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 972      |\n",
            "|    fps              | 1812     |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 88744    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.2e-05  |\n",
            "|    n_updates        | 9685     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 976      |\n",
            "|    fps              | 1811     |\n",
            "|    time_elapsed     | 49       |\n",
            "|    total_timesteps  | 88799    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.02e-05 |\n",
            "|    n_updates        | 9699     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 980      |\n",
            "|    fps              | 1803     |\n",
            "|    time_elapsed     | 49       |\n",
            "|    total_timesteps  | 89261    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000345 |\n",
            "|    n_updates        | 9815     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 984      |\n",
            "|    fps              | 1802     |\n",
            "|    time_elapsed     | 49       |\n",
            "|    total_timesteps  | 89350    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.4e-05  |\n",
            "|    n_updates        | 9837     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 988      |\n",
            "|    fps              | 1798     |\n",
            "|    time_elapsed     | 49       |\n",
            "|    total_timesteps  | 89578    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.59e-05 |\n",
            "|    n_updates        | 9894     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 992      |\n",
            "|    fps              | 1793     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 89829    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000653 |\n",
            "|    n_updates        | 9957     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 996      |\n",
            "|    fps              | 1791     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 89931    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.86e-05 |\n",
            "|    n_updates        | 9982     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1000     |\n",
            "|    fps              | 1790     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 89970    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.98e-05 |\n",
            "|    n_updates        | 9992     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1004     |\n",
            "|    fps              | 1789     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 90000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.56e-05 |\n",
            "|    n_updates        | 9999     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1008     |\n",
            "|    fps              | 1787     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 90139    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 8.05e-05 |\n",
            "|    n_updates        | 10034    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1012     |\n",
            "|    fps              | 1784     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 90295    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.42e-05 |\n",
            "|    n_updates        | 10073    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1016     |\n",
            "|    fps              | 1781     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 90441    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.06e-05 |\n",
            "|    n_updates        | 10110    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1020     |\n",
            "|    fps              | 1779     |\n",
            "|    time_elapsed     | 50       |\n",
            "|    total_timesteps  | 90560    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000991 |\n",
            "|    n_updates        | 10139    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1024     |\n",
            "|    fps              | 1775     |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 90743    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000387 |\n",
            "|    n_updates        | 10185    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1028     |\n",
            "|    fps              | 1773     |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 90893    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000668 |\n",
            "|    n_updates        | 10223    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1032     |\n",
            "|    fps              | 1767     |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 91224    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.32e-05 |\n",
            "|    n_updates        | 10305    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1036     |\n",
            "|    fps              | 1766     |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 91282    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00122  |\n",
            "|    n_updates        | 10320    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1040     |\n",
            "|    fps              | 1763     |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 91444    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000602 |\n",
            "|    n_updates        | 10360    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1044     |\n",
            "|    fps              | 1761     |\n",
            "|    time_elapsed     | 51       |\n",
            "|    total_timesteps  | 91554    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.1e-05  |\n",
            "|    n_updates        | 10388    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1048     |\n",
            "|    fps              | 1759     |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 91647    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.89e-05 |\n",
            "|    n_updates        | 10411    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1052     |\n",
            "|    fps              | 1758     |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 91722    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.13e-05 |\n",
            "|    n_updates        | 10430    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1056     |\n",
            "|    fps              | 1756     |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 91785    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.83e-05 |\n",
            "|    n_updates        | 10446    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1060     |\n",
            "|    fps              | 1752     |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 92085    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.23e-05 |\n",
            "|    n_updates        | 10521    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1064     |\n",
            "|    fps              | 1750     |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 92208    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000984 |\n",
            "|    n_updates        | 10551    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1068     |\n",
            "|    fps              | 1748     |\n",
            "|    time_elapsed     | 52       |\n",
            "|    total_timesteps  | 92304    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000388 |\n",
            "|    n_updates        | 10575    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1072     |\n",
            "|    fps              | 1745     |\n",
            "|    time_elapsed     | 53       |\n",
            "|    total_timesteps  | 92531    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.42e-05 |\n",
            "|    n_updates        | 10632    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1076     |\n",
            "|    fps              | 1737     |\n",
            "|    time_elapsed     | 53       |\n",
            "|    total_timesteps  | 93035    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00101  |\n",
            "|    n_updates        | 10758    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1080     |\n",
            "|    fps              | 1735     |\n",
            "|    time_elapsed     | 53       |\n",
            "|    total_timesteps  | 93179    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.64e-05 |\n",
            "|    n_updates        | 10794    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1084     |\n",
            "|    fps              | 1663     |\n",
            "|    time_elapsed     | 58       |\n",
            "|    total_timesteps  | 96961    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0025   |\n",
            "|    n_updates        | 11740    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1088     |\n",
            "|    fps              | 1657     |\n",
            "|    time_elapsed     | 58       |\n",
            "|    total_timesteps  | 97456    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000102 |\n",
            "|    n_updates        | 11863    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1092     |\n",
            "|    fps              | 1650     |\n",
            "|    time_elapsed     | 59       |\n",
            "|    total_timesteps  | 97991    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.38e-05 |\n",
            "|    n_updates        | 11997    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1096     |\n",
            "|    fps              | 1649     |\n",
            "|    time_elapsed     | 59       |\n",
            "|    total_timesteps  | 98122    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000167 |\n",
            "|    n_updates        | 12030    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1100     |\n",
            "|    fps              | 1648     |\n",
            "|    time_elapsed     | 59       |\n",
            "|    total_timesteps  | 98191    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.89e-05 |\n",
            "|    n_updates        | 12047    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1104     |\n",
            "|    fps              | 1646     |\n",
            "|    time_elapsed     | 59       |\n",
            "|    total_timesteps  | 98302    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0042   |\n",
            "|    n_updates        | 12075    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1108     |\n",
            "|    fps              | 1645     |\n",
            "|    time_elapsed     | 59       |\n",
            "|    total_timesteps  | 98458    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00779  |\n",
            "|    n_updates        | 12114    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1112     |\n",
            "|    fps              | 1638     |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 99025    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000209 |\n",
            "|    n_updates        | 12256    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1116     |\n",
            "|    fps              | 1637     |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 99070    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00072  |\n",
            "|    n_updates        | 12267    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1120     |\n",
            "|    fps              | 1636     |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 99150    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 9.89e-05 |\n",
            "|    n_updates        | 12287    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1124     |\n",
            "|    fps              | 1636     |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 99193    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000151 |\n",
            "|    n_updates        | 12298    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1128     |\n",
            "|    fps              | 1634     |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 99373    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00011  |\n",
            "|    n_updates        | 12343    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1132     |\n",
            "|    fps              | 1632     |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 99523    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00156  |\n",
            "|    n_updates        | 12380    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1136     |\n",
            "|    fps              | 1631     |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 99613    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.44e-05 |\n",
            "|    n_updates        | 12403    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1140     |\n",
            "|    fps              | 1630     |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 99661    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.34e-05 |\n",
            "|    n_updates        | 12415    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1144     |\n",
            "|    fps              | 1629     |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 99712    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0135   |\n",
            "|    n_updates        | 12427    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1148     |\n",
            "|    fps              | 1628     |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 99793    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000173 |\n",
            "|    n_updates        | 12448    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1152     |\n",
            "|    fps              | 1627     |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 99922    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000162 |\n",
            "|    n_updates        | 12480    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1156     |\n",
            "|    fps              | 1626     |\n",
            "|    time_elapsed     | 61       |\n",
            "|    total_timesteps  | 99989    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000135 |\n",
            "|    n_updates        | 12497    |\n",
            "----------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1263 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 1    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 933         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009150328 |\n",
            "|    clip_fraction        | 0.0128      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.689      |\n",
            "|    explained_variance   | -0.729      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.123       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00185    |\n",
            "|    value_loss           | 0.213       |\n",
            "-----------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 785          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063372636 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.673       |\n",
            "|    explained_variance   | 0.054        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0051       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00609     |\n",
            "|    value_loss           | 0.0795       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 773         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010675838 |\n",
            "|    clip_fraction        | 0.0753      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.678      |\n",
            "|    explained_variance   | 0.0558      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.152       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0056     |\n",
            "|    value_loss           | 0.162       |\n",
            "-----------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041791387 |\n",
            "|    clip_fraction        | 0.0105       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.683       |\n",
            "|    explained_variance   | -0.0563      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.05         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    value_loss           | 0.0588       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 764          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054760375 |\n",
            "|    clip_fraction        | 0.0101       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.681       |\n",
            "|    explained_variance   | 0.131        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0778       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    value_loss           | 0.218        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 737          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013560244 |\n",
            "|    clip_fraction        | 0.000732     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.679       |\n",
            "|    explained_variance   | -1.15        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00655      |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000988    |\n",
            "|    value_loss           | 0.0188       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 734          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0124293715 |\n",
            "|    clip_fraction        | 0.132        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 0.0117       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00803     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00866     |\n",
            "|    value_loss           | 0.00835      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 735          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023358234 |\n",
            "|    clip_fraction        | 0.00239      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.656       |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000515     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.000378    |\n",
            "|    value_loss           | 0.0379       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 737         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 27          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013204148 |\n",
            "|    clip_fraction        | 0.234       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.661      |\n",
            "|    explained_variance   | -0.00541    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0184      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    value_loss           | 0.000116    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 728         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013165429 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.66       |\n",
            "|    explained_variance   | -0.47       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00857     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0234     |\n",
            "|    value_loss           | 8.38e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 723         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027559359 |\n",
            "|    clip_fraction        | 0.438       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.627      |\n",
            "|    explained_variance   | 0.879       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0738     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0264     |\n",
            "|    value_loss           | 0.000108    |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 725      |\n",
            "|    iterations           | 13       |\n",
            "|    time_elapsed         | 36       |\n",
            "|    total_timesteps      | 26624    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.05921  |\n",
            "|    clip_fraction        | 0.2      |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.483   |\n",
            "|    explained_variance   | -1.29    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | -0.0227  |\n",
            "|    n_updates            | 120      |\n",
            "|    policy_gradient_loss | -0.0175  |\n",
            "|    value_loss           | 3.66e-05 |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 727         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022214785 |\n",
            "|    clip_fraction        | 0.0366      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.396      |\n",
            "|    explained_variance   | -1.11       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0031     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0032     |\n",
            "|    value_loss           | 1.93e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 725          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0132487025 |\n",
            "|    clip_fraction        | 0.108        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.386       |\n",
            "|    explained_variance   | -3.1         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0126      |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.000808    |\n",
            "|    value_loss           | 1.34e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 718         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007918176 |\n",
            "|    clip_fraction        | 0.0201      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.36       |\n",
            "|    explained_variance   | -8.34       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00567    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00267    |\n",
            "|    value_loss           | 9.7e-06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 721          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046433364 |\n",
            "|    clip_fraction        | 0.0204       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.312       |\n",
            "|    explained_variance   | -9.1         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00284      |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    value_loss           | 6.17e-06     |\n",
            "------------------------------------------\n",
            "xxx\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 723         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002377328 |\n",
            "|    clip_fraction        | 0.0161      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.291      |\n",
            "|    explained_variance   | 0.00234     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00126    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | 0.000796    |\n",
            "|    value_loss           | 0.00431     |\n",
            "-----------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 725          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 53           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058396766 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.267       |\n",
            "|    explained_variance   | -0.586       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0104       |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    value_loss           | 0.0104       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 716          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 57           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006876655 |\n",
            "|    clip_fraction        | 0.00176      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | 0.0404       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0364       |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | 0.000327     |\n",
            "|    value_loss           | 0.0798       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 718          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051868754 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.176       |\n",
            "|    explained_variance   | -0.262       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00205      |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    value_loss           | 0.0133       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 720          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 62           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013985888 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.247       |\n",
            "|    explained_variance   | 0.0968       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0495       |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00096     |\n",
            "|    value_loss           | 0.0987       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 721          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018772802 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.228       |\n",
            "|    explained_variance   | -0.0189      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0192       |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00305     |\n",
            "|    value_loss           | 0.0616       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 714         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004874106 |\n",
            "|    clip_fraction        | 0.0659      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.253      |\n",
            "|    explained_variance   | 0.198       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.03        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00149    |\n",
            "|    value_loss           | 0.0443      |\n",
            "-----------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 715          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011540002 |\n",
            "|    clip_fraction        | 0.00874      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.254       |\n",
            "|    explained_variance   | 0.248        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0219       |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.000726    |\n",
            "|    value_loss           | 0.0779       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 716          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011311709 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.209       |\n",
            "|    explained_variance   | 0.248        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0339       |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.000462    |\n",
            "|    value_loss           | 0.0617       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 716          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 77           |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015849739 |\n",
            "|    clip_fraction        | 0.00928      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.148       |\n",
            "|    explained_variance   | -0.315       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0242       |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | 1.64e-05     |\n",
            "|    value_loss           | 0.0407       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 712         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000945525 |\n",
            "|    clip_fraction        | 0.00981     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.114      |\n",
            "|    explained_variance   | -0.036      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0143      |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.000763   |\n",
            "|    value_loss           | 0.0249      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 712          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 83           |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010453329 |\n",
            "|    clip_fraction        | 0.00571      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0749      |\n",
            "|    explained_variance   | 0.0776       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0164       |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.000795    |\n",
            "|    value_loss           | 0.0157       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 713         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002259918 |\n",
            "|    clip_fraction        | 0.0357      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.172      |\n",
            "|    explained_variance   | 0.128       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00553     |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00348    |\n",
            "|    value_loss           | 0.0368      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 714          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015812232 |\n",
            "|    clip_fraction        | 0.00986      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.267       |\n",
            "|    explained_variance   | 0.277        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00726      |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.000139    |\n",
            "|    value_loss           | 0.0285       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 710         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 92          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002418067 |\n",
            "|    clip_fraction        | 0.0152      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.13       |\n",
            "|    explained_variance   | 0.0925      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0387      |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.000778   |\n",
            "|    value_loss           | 0.0747      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006497259 |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.162       |\n",
            "|    explained_variance   | 0.2          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0482       |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    value_loss           | 0.0853       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 712          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032966048 |\n",
            "|    clip_fraction        | 0.0245       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.122       |\n",
            "|    explained_variance   | 0.136        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.048        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000953    |\n",
            "|    value_loss           | 0.0854       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 713          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020220515 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.213       |\n",
            "|    explained_variance   | 0.307        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0699       |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00164     |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029137798 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.286       |\n",
            "|    explained_variance   | 0.115        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00773      |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    value_loss           | 0.00416      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 710         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008687956 |\n",
            "|    clip_fraction        | 0.0535      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.271      |\n",
            "|    explained_variance   | 0.388       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000821    |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00292    |\n",
            "|    value_loss           | 0.00392     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 109          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019686187 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.259       |\n",
            "|    explained_variance   | 0.388        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00464      |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    value_loss           | 0.00752      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 712         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010969121 |\n",
            "|    clip_fraction        | 0.0725      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.232      |\n",
            "|    explained_variance   | 0.564       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00993     |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00344    |\n",
            "|    value_loss           | 0.00388     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 712          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042920248 |\n",
            "|    clip_fraction        | 0.0516       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.228       |\n",
            "|    explained_variance   | 0.524        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00198      |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    value_loss           | 0.00738      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 710          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035714593 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.213       |\n",
            "|    explained_variance   | 0.64         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00242     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    value_loss           | 0.00389      |\n",
            "------------------------------------------\n",
            "xxx\n",
            "xxx\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 710         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 120         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005141847 |\n",
            "|    clip_fraction        | 0.0502      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.184      |\n",
            "|    explained_variance   | 0.67        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.94e-05    |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00125    |\n",
            "|    value_loss           | 0.0038      |\n",
            "-----------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031859789 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.101       |\n",
            "|    explained_variance   | 0.351        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0443       |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    value_loss           | 0.0566       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 712          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 126          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010630942 |\n",
            "|    clip_fraction        | 0.0164       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.093       |\n",
            "|    explained_variance   | 0.512        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0231       |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.000193    |\n",
            "|    value_loss           | 0.0583       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 709          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 129          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010892486 |\n",
            "|    clip_fraction        | 0.00957      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0773      |\n",
            "|    explained_variance   | 0.673        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.128        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000377    |\n",
            "|    value_loss           | 0.188        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 710          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 132          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019398328 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0883      |\n",
            "|    explained_variance   | 0.303        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0935       |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    value_loss           | 0.25         |\n",
            "------------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 135          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021055415 |\n",
            "|    clip_fraction        | 0.0196       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.137       |\n",
            "|    explained_variance   | -0.379       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0115      |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    value_loss           | 0.0406       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 711          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 138          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015259854 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.137       |\n",
            "|    explained_variance   | 0.183        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00532      |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    value_loss           | 0.0294       |\n",
            "------------------------------------------\n",
            "xxx\n",
            "xxx\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 709          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 141          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013716575 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.14        |\n",
            "|    explained_variance   | 0.301        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.109        |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.000396    |\n",
            "|    value_loss           | 0.153        |\n",
            "------------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 659       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.692    |\n",
            "|    explained_variance | -9.48e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -0.013    |\n",
            "|    value_loss         | 0.000485  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 649      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | -52.3    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.176   |\n",
            "|    value_loss         | 0.0645   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 647       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.69     |\n",
            "|    explained_variance | -602      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -0.000226 |\n",
            "|    value_loss         | 1.77e-07  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 652      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.685   |\n",
            "|    explained_variance | -46.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.00405 |\n",
            "|    value_loss         | 5.3e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 643      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.687   |\n",
            "|    explained_variance | -827     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.00152  |\n",
            "|    value_loss         | 1.49e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 644      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.644   |\n",
            "|    explained_variance | -818     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -0.00674 |\n",
            "|    value_loss         | 9.47e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 641      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.663   |\n",
            "|    explained_variance | -755     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.00184  |\n",
            "|    value_loss         | 8.41e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 646      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.62    |\n",
            "|    explained_variance | -295     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.00416  |\n",
            "|    value_loss         | 7.68e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 641      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.587   |\n",
            "|    explained_variance | -30.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.0029   |\n",
            "|    value_loss         | 6.64e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 643      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.54    |\n",
            "|    explained_variance | -307     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.00114  |\n",
            "|    value_loss         | 2.47e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 627       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.577    |\n",
            "|    explained_variance | -1.76e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 0.00662   |\n",
            "|    value_loss         | 0.000268  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.268   |\n",
            "|    explained_variance | -13      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.00041  |\n",
            "|    value_loss         | 5.13e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 604      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.556   |\n",
            "|    explained_variance | -53.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.00152  |\n",
            "|    value_loss         | 3.21e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 608       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.601    |\n",
            "|    explained_variance | -1.12e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -0.000196 |\n",
            "|    value_loss         | 0.000216  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.67    |\n",
            "|    explained_variance | -23      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.00769  |\n",
            "|    value_loss         | 0.00028  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -569     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.00453  |\n",
            "|    value_loss         | 5.32e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 615      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | -575     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.00217  |\n",
            "|    value_loss         | 4.28e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 617       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.691    |\n",
            "|    explained_variance | -1.55e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -0.0064   |\n",
            "|    value_loss         | 8.67e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 618       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.693    |\n",
            "|    explained_variance | -1.77e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 0.00272   |\n",
            "|    value_loss         | 2.41e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 620       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.693    |\n",
            "|    explained_variance | -2.69e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 0.00137   |\n",
            "|    value_loss         | 9.86e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 621      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.685   |\n",
            "|    explained_variance | -118     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -0.00462 |\n",
            "|    value_loss         | 4.74e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 621       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.682    |\n",
            "|    explained_variance | -6.49e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | -0.00588  |\n",
            "|    value_loss         | 0.000105  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 622      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | -360     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.00128  |\n",
            "|    value_loss         | 6.61e-06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 622       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.687    |\n",
            "|    explained_variance | -1.15e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 0.00217   |\n",
            "|    value_loss         | 1.29e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 623      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.684   |\n",
            "|    explained_variance | -209     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.00335  |\n",
            "|    value_loss         | 2.88e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 617       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.691    |\n",
            "|    explained_variance | -3.38e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 0.000377  |\n",
            "|    value_loss         | 1.81e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.677   |\n",
            "|    explained_variance | -626     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.00836  |\n",
            "|    value_loss         | 0.000126 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 608       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.687    |\n",
            "|    explained_variance | -125      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | -0.000668 |\n",
            "|    value_loss         | 2.27e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 607       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.691    |\n",
            "|    explained_variance | -1.35e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 0.00341   |\n",
            "|    value_loss         | 0.000221  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 608       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.688    |\n",
            "|    explained_variance | -3.64e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 0.00571   |\n",
            "|    value_loss         | 9.79e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 608      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.684   |\n",
            "|    explained_variance | 0.637    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | -0.00571 |\n",
            "|    value_loss         | 8.21e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 609      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -1.69    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.0155  |\n",
            "|    value_loss         | 0.000796 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 608      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | -11.3    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.0236   |\n",
            "|    value_loss         | 0.00197  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.645   |\n",
            "|    explained_variance | -6.29    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 0.0396   |\n",
            "|    value_loss         | 0.00199  |\n",
            "------------------------------------\n",
            "xxx\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.269   |\n",
            "|    explained_variance | 0.287    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -0.0122  |\n",
            "|    value_loss         | 0.0305   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 611      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.269   |\n",
            "|    explained_variance | -1.01    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.0165  |\n",
            "|    value_loss         | 0.000181 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.28    |\n",
            "|    explained_variance | -15.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.00481  |\n",
            "|    value_loss         | 0.000433 |\n",
            "------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.17     |\n",
            "|    explained_variance | -4.41     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | -0.000671 |\n",
            "|    value_loss         | 0.000322  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.362   |\n",
            "|    explained_variance | 0.786    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -0.00186 |\n",
            "|    value_loss         | 0.000372 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.276    |\n",
            "|    explained_variance | 0.838     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -0.000646 |\n",
            "|    value_loss         | 0.000156  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 20500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.172   |\n",
            "|    explained_variance | -2.16    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | 0.000685 |\n",
            "|    value_loss         | 0.000347 |\n",
            "------------------------------------\n",
            "xxx\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 605      |\n",
            "|    iterations         | 4200     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 21000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.216   |\n",
            "|    explained_variance | 0.359    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4199     |\n",
            "|    policy_loss        | 5.01e-05 |\n",
            "|    value_loss         | 9.19e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 606      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.102   |\n",
            "|    explained_variance | -14.3    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | 4.52e-05 |\n",
            "|    value_loss         | 3.03e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 608      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0443  |\n",
            "|    explained_variance | 0.618    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | 1.43e-05 |\n",
            "|    value_loss         | 4.95e-06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 609       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0467   |\n",
            "|    explained_variance | -6.54     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | -0.000146 |\n",
            "|    value_loss         | 0.000415  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 4600     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 23000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0516  |\n",
            "|    explained_variance | 0.819    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4599     |\n",
            "|    policy_loss        | 5.47e-05 |\n",
            "|    value_loss         | 4.35e-05 |\n",
            "------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 610       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.141    |\n",
            "|    explained_variance | -1.55     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -3.62e-05 |\n",
            "|    value_loss         | 0.0531    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0387   |\n",
            "|    explained_variance | -3.55e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -0.00972  |\n",
            "|    value_loss         | 0.000131  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.109   |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | 6.35e-06 |\n",
            "|    value_loss         | 9.51e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0755  |\n",
            "|    explained_variance | -44.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | 0.000469 |\n",
            "|    value_loss         | 0.00143  |\n",
            "------------------------------------\n",
            "xxx\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 5100     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 25500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0345  |\n",
            "|    explained_variance | -8.62    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5099     |\n",
            "|    policy_loss        | 0.000259 |\n",
            "|    value_loss         | 0.00339  |\n",
            "------------------------------------\n",
            "xxx\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 5200     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0905  |\n",
            "|    explained_variance | -0.392   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5199     |\n",
            "|    policy_loss        | 0.000686 |\n",
            "|    value_loss         | 0.00178  |\n",
            "------------------------------------\n",
            "xxx\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0302  |\n",
            "|    explained_variance | 0.36     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | 0.000721 |\n",
            "|    value_loss         | 0.19     |\n",
            "------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0375   |\n",
            "|    explained_variance | 0.651     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | -0.000482 |\n",
            "|    value_loss         | 0.0116    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 614      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0253  |\n",
            "|    explained_variance | -20.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5499     |\n",
            "|    policy_loss        | 2.12e-05 |\n",
            "|    value_loss         | 3.71e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0183   |\n",
            "|    explained_variance | -62.7     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -6.31e-06 |\n",
            "|    value_loss         | 6.81e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 607       |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0535   |\n",
            "|    explained_variance | -1.55e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | 6.4e-06   |\n",
            "|    value_loss         | 3.84e-06  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 607       |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.017    |\n",
            "|    explained_variance | -0.111    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | -7.58e-05 |\n",
            "|    value_loss         | 0.00119   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 608      |\n",
            "|    iterations         | 5900     |\n",
            "|    time_elapsed       | 48       |\n",
            "|    total_timesteps    | 29500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00994 |\n",
            "|    explained_variance | -300     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5899     |\n",
            "|    policy_loss        | 2.12e-06 |\n",
            "|    value_loss         | 3.6e-06  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 608       |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0153   |\n",
            "|    explained_variance | -26.5     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -2.17e-06 |\n",
            "|    value_loss         | 1.56e-06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 609      |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00968 |\n",
            "|    explained_variance | -5.81    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | 3.74e-06 |\n",
            "|    value_loss         | 9.52e-06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 609       |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 50        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00881  |\n",
            "|    explained_variance | -11.6     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | -1.28e-06 |\n",
            "|    value_loss         | 2.94e-06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0151  |\n",
            "|    explained_variance | -817     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | -9.5e-06 |\n",
            "|    value_loss         | 1.99e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 610       |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.042    |\n",
            "|    explained_variance | -218      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | -1.68e-05 |\n",
            "|    value_loss         | 2.67e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0152   |\n",
            "|    explained_variance | -56       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | -1.48e-05 |\n",
            "|    value_loss         | 6.96e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 6600      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0284   |\n",
            "|    explained_variance | -157      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6599      |\n",
            "|    policy_loss        | -2.97e-05 |\n",
            "|    value_loss         | 4.54e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0367   |\n",
            "|    explained_variance | -294      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -2.88e-05 |\n",
            "|    value_loss         | 4.59e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 6800     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0159  |\n",
            "|    explained_variance | 0.279    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6799     |\n",
            "|    policy_loss        | 5.06e-07 |\n",
            "|    value_loss         | 7.13e-08 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 6900      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 34500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00954  |\n",
            "|    explained_variance | -1.85     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6899      |\n",
            "|    policy_loss        | -4.06e-07 |\n",
            "|    value_loss         | 1.36e-07  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0155  |\n",
            "|    explained_variance | -97.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | 8.05e-06 |\n",
            "|    value_loss         | 1.24e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 58       |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0157  |\n",
            "|    explained_variance | -259     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | 8.02e-07 |\n",
            "|    value_loss         | 7.89e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 608      |\n",
            "|    iterations         | 7200     |\n",
            "|    time_elapsed       | 59       |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00759 |\n",
            "|    explained_variance | -64.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7199     |\n",
            "|    policy_loss        | 3.24e-06 |\n",
            "|    value_loss         | 1.4e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 608      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 59       |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0224  |\n",
            "|    explained_variance | -220     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | 1.72e-05 |\n",
            "|    value_loss         | 3.39e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 609      |\n",
            "|    iterations         | 7400     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0825  |\n",
            "|    explained_variance | -3.2e+03 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7399     |\n",
            "|    policy_loss        | 0.000117 |\n",
            "|    value_loss         | 9.36e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 610      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 61       |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0416  |\n",
            "|    explained_variance | -877     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 4.16e-05 |\n",
            "|    value_loss         | 4.93e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 610       |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.037    |\n",
            "|    explained_variance | -4.38e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 3.88e-05  |\n",
            "|    value_loss         | 6.3e-05   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 611      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 62       |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0804  |\n",
            "|    explained_variance | -183     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | 6.42e-05 |\n",
            "|    value_loss         | 1.59e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0734   |\n",
            "|    explained_variance | -2.35e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | 3.38e-05  |\n",
            "|    value_loss         | 3.36e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0513   |\n",
            "|    explained_variance | -1.84e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | 3.83e-05  |\n",
            "|    value_loss         | 2.73e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 8000     |\n",
            "|    time_elapsed       | 65       |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0203  |\n",
            "|    explained_variance | -47.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7999     |\n",
            "|    policy_loss        | 7.23e-07 |\n",
            "|    value_loss         | 2.4e-06  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0123   |\n",
            "|    explained_variance | -6.1      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | -3.39e-05 |\n",
            "|    value_loss         | 0.000523  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00818  |\n",
            "|    explained_variance | -40.9     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | -1.13e-05 |\n",
            "|    value_loss         | 0.000306  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 614      |\n",
            "|    iterations         | 8300     |\n",
            "|    time_elapsed       | 67       |\n",
            "|    total_timesteps    | 41500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0131  |\n",
            "|    explained_variance | 0.832    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8299     |\n",
            "|    policy_loss        | -1.3e-06 |\n",
            "|    value_loss         | 6.35e-07 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00933  |\n",
            "|    explained_variance | -1.08e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | -1.2e-06  |\n",
            "|    value_loss         | 1.24e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00741  |\n",
            "|    explained_variance | -5.61e+14 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -7.57e-06 |\n",
            "|    value_loss         | 0.000612  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0185   |\n",
            "|    explained_variance | -9.49e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | -0.000116 |\n",
            "|    value_loss         | 0.00248   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 610       |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0102   |\n",
            "|    explained_variance | -75.6     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | -2.02e-05 |\n",
            "|    value_loss         | 0.000543  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 610       |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00344  |\n",
            "|    explained_variance | 0.106     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | -0.000104 |\n",
            "|    value_loss         | 0.152     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00246  |\n",
            "|    explained_variance | -1e+03    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | -8.42e-06 |\n",
            "|    value_loss         | 0.000892  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 611      |\n",
            "|    iterations         | 9000     |\n",
            "|    time_elapsed       | 73       |\n",
            "|    total_timesteps    | 45000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00208 |\n",
            "|    explained_variance | -70.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8999     |\n",
            "|    policy_loss        | 5.09e-07 |\n",
            "|    value_loss         | 5.61e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00376 |\n",
            "|    explained_variance | -0.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | 0.000182 |\n",
            "|    value_loss         | 0.668    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 612      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 75       |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00387 |\n",
            "|    explained_variance | -7.84    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | 3.74e-06 |\n",
            "|    value_loss         | 0.000116 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00401  |\n",
            "|    explained_variance | -2.24e+13 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | -2.3e-05  |\n",
            "|    value_loss         | 0.00269   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 9400     |\n",
            "|    time_elapsed       | 76       |\n",
            "|    total_timesteps    | 47000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00201 |\n",
            "|    explained_variance | 0.816    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9399     |\n",
            "|    policy_loss        | -1.1e-06 |\n",
            "|    value_loss         | 2.54e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 614      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 77       |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00094 |\n",
            "|    explained_variance | -29.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | 3.79e-07 |\n",
            "|    value_loss         | 0.00013  |\n",
            "------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000975 |\n",
            "|    explained_variance | 0.849     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9599      |\n",
            "|    policy_loss        | -3.44e-07 |\n",
            "|    value_loss         | 1.57e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 9700      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 48500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00122  |\n",
            "|    explained_variance | 0.965     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9699      |\n",
            "|    policy_loss        | -2.56e-07 |\n",
            "|    value_loss         | 4.97e-06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 614      |\n",
            "|    iterations         | 9800     |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 49000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00101 |\n",
            "|    explained_variance | -4.05    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9799     |\n",
            "|    policy_loss        | -1.7e-06 |\n",
            "|    value_loss         | 0.000377 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00091  |\n",
            "|    explained_variance | -41       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | -5.25e-07 |\n",
            "|    value_loss         | 8.15e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000837 |\n",
            "|    explained_variance | -454      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | 1.08e-06  |\n",
            "|    value_loss         | 0.000217  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000908 |\n",
            "|    explained_variance | -18.3     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | -2.68e-06 |\n",
            "|    value_loss         | 0.00102   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 611      |\n",
            "|    iterations         | 10200    |\n",
            "|    time_elapsed       | 83       |\n",
            "|    total_timesteps    | 51000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00114 |\n",
            "|    explained_variance | -147     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10199    |\n",
            "|    policy_loss        | 4.67e-06 |\n",
            "|    value_loss         | 0.00299  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000622 |\n",
            "|    explained_variance | -58.6     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | -2.51e-07 |\n",
            "|    value_loss         | 0.000607  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 611       |\n",
            "|    iterations         | 10400     |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 52000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000823 |\n",
            "|    explained_variance | -187      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10399     |\n",
            "|    policy_loss        | 1.24e-06  |\n",
            "|    value_loss         | 0.00632   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000571 |\n",
            "|    explained_variance | -9.61     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 1.85e-06  |\n",
            "|    value_loss         | 0.00168   |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 10600     |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 53000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000564 |\n",
            "|    explained_variance | -1.31     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10599     |\n",
            "|    policy_loss        | -4.84e-07 |\n",
            "|    value_loss         | 0.00014   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000365 |\n",
            "|    explained_variance | -2.06     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | -6.52e-07 |\n",
            "|    value_loss         | 0.000516  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 10800     |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 54000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000316 |\n",
            "|    explained_variance | 0.289     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10799     |\n",
            "|    policy_loss        | 8.67e-08  |\n",
            "|    value_loss         | 2.6e-05   |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 10900     |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 54500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00232  |\n",
            "|    explained_variance | -0.743    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10899     |\n",
            "|    policy_loss        | -3.15e-05 |\n",
            "|    value_loss         | 0.0137    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 614      |\n",
            "|    iterations         | 11000    |\n",
            "|    time_elapsed       | 89       |\n",
            "|    total_timesteps    | 55000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00179 |\n",
            "|    explained_variance | -2.07    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10999    |\n",
            "|    policy_loss        | 4.05e-06 |\n",
            "|    value_loss         | 0.000641 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 614      |\n",
            "|    iterations         | 11100    |\n",
            "|    time_elapsed       | 90       |\n",
            "|    total_timesteps    | 55500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00151 |\n",
            "|    explained_variance | -0.791   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11099    |\n",
            "|    policy_loss        | 4.01e-06 |\n",
            "|    value_loss         | 0.000993 |\n",
            "------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 11200     |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 56000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00113  |\n",
            "|    explained_variance | -0.228    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11199     |\n",
            "|    policy_loss        | -2.32e-05 |\n",
            "|    value_loss         | 0.189     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 615      |\n",
            "|    iterations         | 11300    |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 56500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00396 |\n",
            "|    explained_variance | 0.882    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11299    |\n",
            "|    policy_loss        | 1.31e-06 |\n",
            "|    value_loss         | 8.09e-06 |\n",
            "------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 92        |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000848 |\n",
            "|    explained_variance | 0.624     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 1.25e-06  |\n",
            "|    value_loss         | 0.000237  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0015   |\n",
            "|    explained_variance | -0.656    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | -2.07e-06 |\n",
            "|    value_loss         | 0.000264  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 11600    |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 58000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00106 |\n",
            "|    explained_variance | 0.85     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11599    |\n",
            "|    policy_loss        | 4.8e-08  |\n",
            "|    value_loss         | 2.72e-07 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 11700     |\n",
            "|    time_elapsed       | 95        |\n",
            "|    total_timesteps    | 58500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00124  |\n",
            "|    explained_variance | -1.01e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11699     |\n",
            "|    policy_loss        | -8.39e-08 |\n",
            "|    value_loss         | 7.06e-07  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00207  |\n",
            "|    explained_variance | -4.62e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | 3.71e-08  |\n",
            "|    value_loss         | 1.64e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 11900     |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 59500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00133  |\n",
            "|    explained_variance | -5.28e+05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11899     |\n",
            "|    policy_loss        | -2.14e-07 |\n",
            "|    value_loss         | 2.79e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 12000     |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 60000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00102  |\n",
            "|    explained_variance | -1.51e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11999     |\n",
            "|    policy_loss        | -1.25e-07 |\n",
            "|    value_loss         | 2.31e-06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 12100    |\n",
            "|    time_elapsed       | 98       |\n",
            "|    total_timesteps    | 60500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00153 |\n",
            "|    explained_variance | 0.659    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12099    |\n",
            "|    policy_loss        | 3.13e-08 |\n",
            "|    value_loss         | 5.66e-08 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 12200     |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 61000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00176  |\n",
            "|    explained_variance | -2.29e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12199     |\n",
            "|    policy_loss        | -2.27e-07 |\n",
            "|    value_loss         | 4.05e-06  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 12300    |\n",
            "|    time_elapsed       | 100      |\n",
            "|    total_timesteps    | 61500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00102 |\n",
            "|    explained_variance | -423     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12299    |\n",
            "|    policy_loss        | -2.1e-07 |\n",
            "|    value_loss         | 7.41e-06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 62000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000643 |\n",
            "|    explained_variance | -200      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | -1.91e-07 |\n",
            "|    value_loss         | 1.09e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00101  |\n",
            "|    explained_variance | -308      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | -3.51e-07 |\n",
            "|    value_loss         | 2.29e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 12600     |\n",
            "|    time_elapsed       | 102       |\n",
            "|    total_timesteps    | 63000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000692 |\n",
            "|    explained_variance | -80.2     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12599     |\n",
            "|    policy_loss        | -1.34e-07 |\n",
            "|    value_loss         | 5.83e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 12700     |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 63500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000547 |\n",
            "|    explained_variance | -481      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12699     |\n",
            "|    policy_loss        | -2.29e-07 |\n",
            "|    value_loss         | 2.97e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 12800     |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 64000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000783 |\n",
            "|    explained_variance | -236      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12799     |\n",
            "|    policy_loss        | -1.79e-07 |\n",
            "|    value_loss         | 6.01e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000888 |\n",
            "|    explained_variance | -2.21e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | -1.65e-07 |\n",
            "|    value_loss         | 8.67e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 13000     |\n",
            "|    time_elapsed       | 105       |\n",
            "|    total_timesteps    | 65000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00055  |\n",
            "|    explained_variance | -9.99e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12999     |\n",
            "|    policy_loss        | -1.16e-07 |\n",
            "|    value_loss         | 8.03e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000349 |\n",
            "|    explained_variance | -541      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | -7.31e-08 |\n",
            "|    value_loss         | 6.42e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 13200     |\n",
            "|    time_elapsed       | 107       |\n",
            "|    total_timesteps    | 66000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000535 |\n",
            "|    explained_variance | -604      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13199     |\n",
            "|    policy_loss        | -1.64e-07 |\n",
            "|    value_loss         | 1.87e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000389 |\n",
            "|    explained_variance | -694      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | -5.69e-08 |\n",
            "|    value_loss         | 3.89e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 13400     |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 67000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000315 |\n",
            "|    explained_variance | -1.17e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13399     |\n",
            "|    policy_loss        | -1.11e-07 |\n",
            "|    value_loss         | 2.41e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 13500     |\n",
            "|    time_elapsed       | 110       |\n",
            "|    total_timesteps    | 67500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000465 |\n",
            "|    explained_variance | -188      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13499     |\n",
            "|    policy_loss        | -9.85e-08 |\n",
            "|    value_loss         | 5.7e-06   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 13600     |\n",
            "|    time_elapsed       | 110       |\n",
            "|    total_timesteps    | 68000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000556 |\n",
            "|    explained_variance | -1.07e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13599     |\n",
            "|    policy_loss        | -8.44e-08 |\n",
            "|    value_loss         | 7.32e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 111       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000335 |\n",
            "|    explained_variance | -6.89e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | -6.56e-08 |\n",
            "|    value_loss         | 7.45e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000375 |\n",
            "|    explained_variance | -2.66e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | -5.99e-08 |\n",
            "|    value_loss         | 3.69e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 13900     |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 69500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000629 |\n",
            "|    explained_variance | -1.41e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13899     |\n",
            "|    policy_loss        | -1.87e-07 |\n",
            "|    value_loss         | 1.68e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 14000     |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 70000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000432 |\n",
            "|    explained_variance | -4.14e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 13999     |\n",
            "|    policy_loss        | -5.49e-08 |\n",
            "|    value_loss         | 3.39e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 14100     |\n",
            "|    time_elapsed       | 114       |\n",
            "|    total_timesteps    | 70500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000338 |\n",
            "|    explained_variance | -2.24e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14099     |\n",
            "|    policy_loss        | -1.18e-07 |\n",
            "|    value_loss         | 2.37e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 14200     |\n",
            "|    time_elapsed       | 115       |\n",
            "|    total_timesteps    | 71000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000537 |\n",
            "|    explained_variance | -188      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14199     |\n",
            "|    policy_loss        | -1.19e-07 |\n",
            "|    value_loss         | 5.81e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 116       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000663 |\n",
            "|    explained_variance | -1.14e+05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | -8.67e-08 |\n",
            "|    value_loss         | 6.42e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 14400     |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 72000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000364 |\n",
            "|    explained_variance | -1.2e+03  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14399     |\n",
            "|    policy_loss        | -6.68e-08 |\n",
            "|    value_loss         | 6.46e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 14500     |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 72500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000417 |\n",
            "|    explained_variance | -1.04e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14499     |\n",
            "|    policy_loss        | -4.18e-08 |\n",
            "|    value_loss         | 1.54e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 14600     |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 73000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000771 |\n",
            "|    explained_variance | -1.71e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14599     |\n",
            "|    policy_loss        | -2.1e-07  |\n",
            "|    value_loss         | 1.33e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 14700     |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 73500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000494 |\n",
            "|    explained_variance | -3.03e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14699     |\n",
            "|    policy_loss        | -3.8e-08  |\n",
            "|    value_loss         | 1.91e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 14800     |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 74000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000368 |\n",
            "|    explained_variance | -1.93e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14799     |\n",
            "|    policy_loss        | -1.11e-07 |\n",
            "|    value_loss         | 1.71e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 14900     |\n",
            "|    time_elapsed       | 121       |\n",
            "|    total_timesteps    | 74500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000643 |\n",
            "|    explained_variance | -266      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14899     |\n",
            "|    policy_loss        | -1.35e-07 |\n",
            "|    value_loss         | 4.76e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 15000     |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 75000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000831 |\n",
            "|    explained_variance | -2.04e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 14999     |\n",
            "|    policy_loss        | -8.81e-08 |\n",
            "|    value_loss         | 5.3e-06   |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 15100     |\n",
            "|    time_elapsed       | 123       |\n",
            "|    total_timesteps    | 75500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000615 |\n",
            "|    explained_variance | -312      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15099     |\n",
            "|    policy_loss        | -6.27e-07 |\n",
            "|    value_loss         | 0.000143  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 613      |\n",
            "|    iterations         | 15200    |\n",
            "|    time_elapsed       | 123      |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00036 |\n",
            "|    explained_variance | -11      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15199    |\n",
            "|    policy_loss        | 1.79e-06 |\n",
            "|    value_loss         | 0.0034   |\n",
            "------------------------------------\n",
            "xxx\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 15300     |\n",
            "|    time_elapsed       | 124       |\n",
            "|    total_timesteps    | 76500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000127 |\n",
            "|    explained_variance | -24.5     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15299     |\n",
            "|    policy_loss        | -3.02e-06 |\n",
            "|    value_loss         | 0.102     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 15400     |\n",
            "|    time_elapsed       | 125       |\n",
            "|    total_timesteps    | 77000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.21e-05 |\n",
            "|    explained_variance | -478      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15399     |\n",
            "|    policy_loss        | -1.26e-06 |\n",
            "|    value_loss         | 0.0452    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000165 |\n",
            "|    explained_variance | 0.945     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | -7.68e-08 |\n",
            "|    value_loss         | 3.55e-05  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 15600     |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 78000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000126 |\n",
            "|    explained_variance | -946      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15599     |\n",
            "|    policy_loss        | -2.47e-07 |\n",
            "|    value_loss         | 0.000708  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.77e-05 |\n",
            "|    explained_variance | -0.244    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | -8.1e-09  |\n",
            "|    value_loss         | 6.9e-06   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 128       |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.48e-05 |\n",
            "|    explained_variance | -3.29     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | 5.75e-10  |\n",
            "|    value_loss         | 6.18e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 129       |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.18e-05 |\n",
            "|    explained_variance | -2.57     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | -1.53e-09 |\n",
            "|    value_loss         | 2.11e-07  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 16000     |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 80000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.38e-05 |\n",
            "|    explained_variance | -0.169    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 15999     |\n",
            "|    policy_loss        | -3.08e-08 |\n",
            "|    value_loss         | 5.22e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 131       |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.03e-05 |\n",
            "|    explained_variance | -0.535    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 9.29e-10  |\n",
            "|    value_loss         | 7.99e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 132       |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.39e-05 |\n",
            "|    explained_variance | -3.52     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | 1.17e-09  |\n",
            "|    value_loss         | 1.79e-07  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 612       |\n",
            "|    iterations         | 16300     |\n",
            "|    time_elapsed       | 132       |\n",
            "|    total_timesteps    | 81500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.9e-05  |\n",
            "|    explained_variance | -0.132    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16299     |\n",
            "|    policy_loss        | -6.09e-10 |\n",
            "|    value_loss         | 3.52e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.09e-05 |\n",
            "|    explained_variance | 0.72      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | 8.92e-11  |\n",
            "|    value_loss         | 1.14e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 16500     |\n",
            "|    time_elapsed       | 134       |\n",
            "|    total_timesteps    | 82500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.37e-05 |\n",
            "|    explained_variance | 0.442     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16499     |\n",
            "|    policy_loss        | 5.55e-10  |\n",
            "|    value_loss         | 2.33e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.56e-05 |\n",
            "|    explained_variance | 0.585     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 5.53e-10  |\n",
            "|    value_loss         | 3.36e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 136       |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.66e-05 |\n",
            "|    explained_variance | 0.706     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | -3.78e-10 |\n",
            "|    value_loss         | 1.58e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 16800     |\n",
            "|    time_elapsed       | 136       |\n",
            "|    total_timesteps    | 84000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.59e-05 |\n",
            "|    explained_variance | 0.965     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16799     |\n",
            "|    policy_loss        | -6.91e-11 |\n",
            "|    value_loss         | 5.59e-10  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 137       |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.75e-05 |\n",
            "|    explained_variance | -0.922    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -2.84e-09 |\n",
            "|    value_loss         | 6.38e-07  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 17000     |\n",
            "|    time_elapsed       | 138       |\n",
            "|    total_timesteps    | 85000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.73e-05 |\n",
            "|    explained_variance | 0.819     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16999     |\n",
            "|    policy_loss        | 5.75e-10  |\n",
            "|    value_loss         | 3.42e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.49e-05 |\n",
            "|    explained_variance | 0.67      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | -4.42e-10 |\n",
            "|    value_loss         | 2.16e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 17200     |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 86000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.21e-05 |\n",
            "|    explained_variance | 0.963     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17199     |\n",
            "|    policy_loss        | -2.19e-10 |\n",
            "|    value_loss         | 3.74e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 140       |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.28e-05 |\n",
            "|    explained_variance | -0.0885   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | -2.19e-08 |\n",
            "|    value_loss         | 2.76e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 17400     |\n",
            "|    time_elapsed       | 141       |\n",
            "|    total_timesteps    | 87000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.98e-05 |\n",
            "|    explained_variance | 0.863     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17399     |\n",
            "|    policy_loss        | 5.81e-10  |\n",
            "|    value_loss         | 2.98e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 142       |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.36e-05 |\n",
            "|    explained_variance | 0.662     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | 5.13e-10  |\n",
            "|    value_loss         | 3.03e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 17600     |\n",
            "|    time_elapsed       | 143       |\n",
            "|    total_timesteps    | 88000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.91e-05 |\n",
            "|    explained_variance | 0.944     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17599     |\n",
            "|    policy_loss        | -2.78e-10 |\n",
            "|    value_loss         | 6.53e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 144       |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.14e-05 |\n",
            "|    explained_variance | 0.856     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | 5.59e-11  |\n",
            "|    value_loss         | 1.38e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 89000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.28e-05 |\n",
            "|    explained_variance | 0.989     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | 1.36e-10  |\n",
            "|    value_loss         | 1.46e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 613       |\n",
            "|    iterations         | 17900     |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 89500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.52e-05 |\n",
            "|    explained_variance | 0.729     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17899     |\n",
            "|    policy_loss        | 5.87e-10  |\n",
            "|    value_loss         | 3.66e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 18000     |\n",
            "|    time_elapsed       | 146       |\n",
            "|    total_timesteps    | 90000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.66e-05 |\n",
            "|    explained_variance | 0.818     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17999     |\n",
            "|    policy_loss        | -3.88e-10 |\n",
            "|    value_loss         | 1.61e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.61e-05 |\n",
            "|    explained_variance | 0.959     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | -1.34e-10 |\n",
            "|    value_loss         | 1.59e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 18200     |\n",
            "|    time_elapsed       | 148       |\n",
            "|    total_timesteps    | 91000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.66e-05 |\n",
            "|    explained_variance | -0.901    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18199     |\n",
            "|    policy_loss        | -3.81e-09 |\n",
            "|    value_loss         | 1.14e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 18300     |\n",
            "|    time_elapsed       | 148       |\n",
            "|    total_timesteps    | 91500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.68e-05 |\n",
            "|    explained_variance | 0.823     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18299     |\n",
            "|    policy_loss        | 7.37e-10  |\n",
            "|    value_loss         | 5.6e-08   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 149       |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.48e-05 |\n",
            "|    explained_variance | 0.732     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | -4.66e-10 |\n",
            "|    value_loss         | 2.37e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 18500     |\n",
            "|    time_elapsed       | 150       |\n",
            "|    total_timesteps    | 92500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.22e-05 |\n",
            "|    explained_variance | 0.952     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18499     |\n",
            "|    policy_loss        | -2.68e-10 |\n",
            "|    value_loss         | 5.93e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 151       |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.17e-05 |\n",
            "|    explained_variance | -0.17     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | -1.91e-08 |\n",
            "|    value_loss         | 2.06e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 151       |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.92e-05 |\n",
            "|    explained_variance | 0.85      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | 8.59e-10  |\n",
            "|    value_loss         | 6.61e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32e-05 |\n",
            "|    explained_variance | -3.87     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 2.72e-09  |\n",
            "|    value_loss         | 8.43e-07  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 616       |\n",
            "|    iterations         | 18900     |\n",
            "|    time_elapsed       | 153       |\n",
            "|    total_timesteps    | 94500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.91e-05 |\n",
            "|    explained_variance | 0.951     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18899     |\n",
            "|    policy_loss        | -3.43e-10 |\n",
            "|    value_loss         | 1.01e-08  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 616       |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 154       |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.17e-05 |\n",
            "|    explained_variance | 0.916     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | -6.31e-11 |\n",
            "|    value_loss         | 2.43e-09  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 615      |\n",
            "|    iterations         | 19100    |\n",
            "|    time_elapsed       | 155      |\n",
            "|    total_timesteps    | 95500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.2e-05 |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19099    |\n",
            "|    policy_loss        | 2.58e-11 |\n",
            "|    value_loss         | 1.63e-10 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 19200     |\n",
            "|    time_elapsed       | 156       |\n",
            "|    total_timesteps    | 96000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.47e-05 |\n",
            "|    explained_variance | 0.72      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19199     |\n",
            "|    policy_loss        | 5.74e-10  |\n",
            "|    value_loss         | 3.5e-08   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 19300     |\n",
            "|    time_elapsed       | 157       |\n",
            "|    total_timesteps    | 96500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.65e-05 |\n",
            "|    explained_variance | 0.856     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19299     |\n",
            "|    policy_loss        | -3.54e-10 |\n",
            "|    value_loss         | 1.32e-08  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 157       |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.95e-05 |\n",
            "|    explained_variance | -1.99e+04 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | -6.05e-08 |\n",
            "|    value_loss         | 0.000507  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 614       |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 158       |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.64e-05 |\n",
            "|    explained_variance | -23.4     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | -1.2e-07  |\n",
            "|    value_loss         | 0.00213   |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 159       |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000105 |\n",
            "|    explained_variance | -0.174    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | -8.11e-08 |\n",
            "|    value_loss         | 0.00019   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 19700     |\n",
            "|    time_elapsed       | 160       |\n",
            "|    total_timesteps    | 98500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.43e-05 |\n",
            "|    explained_variance | -34.4     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19699     |\n",
            "|    policy_loss        | -7.2e-08  |\n",
            "|    value_loss         | 0.000429  |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 160       |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.68e-05 |\n",
            "|    explained_variance | -1.11     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | -2.59e-07 |\n",
            "|    value_loss         | 0.00177   |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 19900     |\n",
            "|    time_elapsed       | 161       |\n",
            "|    total_timesteps    | 99500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000123 |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19899     |\n",
            "|    policy_loss        | -9.36e-06 |\n",
            "|    value_loss         | 0.944     |\n",
            "-------------------------------------\n",
            "xxx\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 615       |\n",
            "|    iterations         | 20000     |\n",
            "|    time_elapsed       | 162       |\n",
            "|    total_timesteps    | 100000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000137 |\n",
            "|    explained_variance | -2.07     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19999     |\n",
            "|    policy_loss        | -2.12e-07 |\n",
            "|    value_loss         | 0.000781  |\n",
            "-------------------------------------\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[2.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[2.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[2.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[1.]\n",
            "[2.]\n",
            "[1.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "0\n",
            "[0.]\n",
            "1\n",
            "[0.]\n",
            "2\n",
            "[0.]\n",
            "3\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "5\n",
            "[1.]\n",
            "6\n",
            "[0.]\n",
            "7\n",
            "[0.]\n",
            "8\n",
            "[0.]\n",
            "9\n",
            "[0.]\n",
            "10\n",
            "[2.]\n",
            "11\n",
            "[0.]\n",
            "12\n",
            "[0.]\n",
            "13\n",
            "[0.]\n",
            "14\n",
            "[0.]\n",
            "15\n",
            "[0.]\n",
            "16\n",
            "[0.]\n",
            "17\n",
            "[0.]\n",
            "18\n",
            "[0.]\n",
            "19\n",
            "[0.]\n",
            "20\n",
            "[0.]\n",
            "21\n",
            "[0.]\n",
            "22\n",
            "[0.]\n",
            "23\n",
            "[0.]\n",
            "24\n",
            "[0.]\n",
            "25\n",
            "[0.]\n",
            "26\n",
            "[0.]\n",
            "27\n",
            "[0.]\n",
            "28\n",
            "[0.]\n",
            "29\n",
            "[1.]\n",
            "30\n",
            "[0.]\n",
            "31\n",
            "[0.]\n",
            "32\n",
            "[0.]\n",
            "33\n",
            "[0.]\n",
            "34\n",
            "[0.]\n",
            "35\n",
            "[0.]\n",
            "36\n",
            "[0.]\n",
            "37\n",
            "[0.]\n",
            "38\n",
            "[0.]\n",
            "39\n",
            "[0.]\n",
            "40\n",
            "[0.]\n",
            "41\n",
            "xxx\n",
            "[11.]\n",
            "42\n",
            "xxx\n",
            "[11.]\n",
            "43\n",
            "[0.]\n",
            "44\n",
            "[0.]\n",
            "45\n",
            "[0.]\n",
            "46\n",
            "[0.]\n",
            "47\n",
            "[0.]\n",
            "48\n",
            "[0.]\n",
            "49\n",
            "[0.]\n",
            "50\n",
            "[0.]\n",
            "51\n",
            "[0.]\n",
            "52\n",
            "[0.]\n",
            "53\n",
            "[0.]\n",
            "54\n",
            "[0.]\n",
            "55\n",
            "[0.]\n",
            "56\n",
            "[0.]\n",
            "57\n",
            "[0.]\n",
            "58\n",
            "[0.]\n",
            "59\n",
            "[0.]\n",
            "60\n",
            "[0.]\n",
            "61\n",
            "[0.]\n",
            "62\n",
            "[0.]\n",
            "63\n",
            "[0.]\n",
            "64\n",
            "[0.]\n",
            "65\n",
            "[0.]\n",
            "66\n",
            "[0.]\n",
            "67\n",
            "[0.]\n",
            "68\n",
            "[0.]\n",
            "69\n",
            "[0.]\n",
            "70\n",
            "[0.]\n",
            "71\n",
            "[0.]\n",
            "72\n",
            "[0.]\n",
            "73\n",
            "[0.]\n",
            "74\n",
            "[0.]\n",
            "75\n",
            "[0.]\n",
            "76\n",
            "[0.]\n",
            "77\n",
            "[0.]\n",
            "78\n",
            "[0.]\n",
            "79\n",
            "[0.]\n",
            "80\n",
            "[0.]\n",
            "81\n",
            "[0.]\n",
            "82\n",
            "[0.]\n",
            "83\n",
            "[2.]\n",
            "84\n",
            "[0.]\n",
            "85\n",
            "[0.]\n",
            "86\n",
            "[0.]\n",
            "87\n",
            "[4.]\n",
            "88\n",
            "[0.]\n",
            "89\n",
            "[1.]\n",
            "90\n",
            "[0.]\n",
            "91\n",
            "[0.]\n",
            "92\n",
            "[0.]\n",
            "93\n",
            "[0.]\n",
            "94\n",
            "[0.]\n",
            "95\n",
            "[0.]\n",
            "96\n",
            "[1.]\n",
            "97\n",
            "xxx\n",
            "[11.]\n",
            "98\n",
            "[0.]\n",
            "99\n",
            "[1.]\n",
            "0\n",
            "[0.]\n",
            "1\n",
            "[0.]\n",
            "2\n",
            "[0.]\n",
            "3\n",
            "[0.]\n",
            "4\n",
            "[0.]\n",
            "5\n",
            "[1.]\n",
            "6\n",
            "[0.]\n",
            "7\n",
            "[0.]\n",
            "8\n",
            "[0.]\n",
            "9\n",
            "[2.]\n",
            "10\n",
            "[0.]\n",
            "11\n",
            "xxx\n",
            "[11.]\n",
            "12\n",
            "[0.]\n",
            "13\n",
            "[0.]\n",
            "14\n",
            "[0.]\n",
            "15\n",
            "[0.]\n",
            "16\n",
            "[1.]\n",
            "17\n",
            "[3.]\n",
            "18\n",
            "[0.]\n",
            "19\n",
            "[0.]\n",
            "20\n",
            "[0.]\n",
            "21\n",
            "[0.]\n",
            "22\n",
            "[0.]\n",
            "23\n",
            "[0.]\n",
            "24\n",
            "[0.]\n",
            "25\n",
            "[1.]\n",
            "26\n",
            "[0.]\n",
            "27\n",
            "[0.]\n",
            "28\n",
            "[0.]\n",
            "29\n",
            "[0.]\n",
            "30\n",
            "[0.]\n",
            "31\n",
            "[0.]\n",
            "32\n",
            "[0.]\n",
            "33\n",
            "[0.]\n",
            "34\n",
            "[0.]\n",
            "35\n",
            "[0.]\n",
            "36\n",
            "[0.]\n",
            "37\n",
            "[0.]\n",
            "38\n",
            "[3.]\n",
            "39\n",
            "[0.]\n",
            "40\n",
            "[0.]\n",
            "41\n",
            "[0.]\n",
            "42\n",
            "[1.]\n",
            "43\n",
            "[0.]\n",
            "44\n",
            "[0.]\n",
            "45\n",
            "[0.]\n",
            "46\n",
            "[1.]\n",
            "47\n",
            "[0.]\n",
            "48\n",
            "[1.]\n",
            "49\n",
            "[0.]\n",
            "50\n",
            "[0.]\n",
            "51\n",
            "[0.]\n",
            "52\n",
            "[0.]\n",
            "53\n",
            "xxx\n",
            "[5.]\n",
            "54\n",
            "[0.]\n",
            "55\n",
            "[0.]\n",
            "56\n",
            "[0.]\n",
            "57\n",
            "[0.]\n",
            "58\n",
            "[0.]\n",
            "59\n",
            "[0.]\n",
            "60\n",
            "xxx\n",
            "[11.]\n",
            "61\n",
            "[1.]\n",
            "62\n",
            "[3.]\n",
            "63\n",
            "[1.]\n",
            "64\n",
            "xxx\n",
            "[11.]\n",
            "65\n",
            "[0.]\n",
            "66\n",
            "[0.]\n",
            "67\n",
            "[0.]\n",
            "68\n",
            "[0.]\n",
            "69\n",
            "[0.]\n",
            "70\n",
            "[0.]\n",
            "71\n",
            "[0.]\n",
            "72\n",
            "[0.]\n",
            "73\n",
            "[0.]\n",
            "74\n",
            "[1.]\n",
            "75\n",
            "[0.]\n",
            "76\n",
            "[0.]\n",
            "77\n",
            "xxx\n",
            "[11.]\n",
            "78\n",
            "[1.]\n",
            "79\n",
            "[0.]\n",
            "80\n",
            "[0.]\n",
            "81\n",
            "[0.]\n",
            "82\n",
            "[0.]\n",
            "83\n",
            "[0.]\n",
            "84\n",
            "[0.]\n",
            "85\n",
            "[0.]\n",
            "86\n",
            "[0.]\n",
            "87\n",
            "[0.]\n",
            "88\n",
            "[0.]\n",
            "89\n",
            "[1.]\n",
            "90\n",
            "[0.]\n",
            "91\n",
            "[3.]\n",
            "92\n",
            "[0.]\n",
            "93\n",
            "[2.]\n",
            "94\n",
            "[0.]\n",
            "95\n",
            "[1.]\n",
            "96\n",
            "[0.]\n",
            "97\n",
            "[0.]\n",
            "98\n",
            "[0.]\n",
            "99\n"
          ]
        }
      ],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, env):\n",
        "        self.model = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "        self.env=env\n",
        "\n",
        "    def train(self, total_timesteps):\n",
        "        self.model.learn(total_timesteps=total_timesteps)\n",
        "    def calculate_expertise(self, num_episodes=100):\n",
        "        total_rewards = 0\n",
        "        total_rewards_list=[]\n",
        "        for zz in range(num_episodes):\n",
        "            obs = self.env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "\n",
        "            while not done and episode_reward<100:\n",
        "                action, _ = self.model.predict(obs)\n",
        "                obs, reward, done, _ = self.env.step(action)\n",
        "                episode_reward += reward\n",
        "            total_rewards += episode_reward\n",
        "            print(episode_reward)\n",
        "            total_rewards_list.append(episode_reward)\n",
        "\n",
        "        average_reward = total_rewards / num_episodes\n",
        "        return average_reward,total_rewards_list\n",
        "\n",
        "\n",
        "class PPOAgent:\n",
        "    def __init__(self, env):\n",
        "        self.model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "        self.env=env\n",
        "\n",
        "\n",
        "    def train(self, total_timesteps):\n",
        "        self.model.learn(total_timesteps=total_timesteps)\n",
        "    def calculate_expertise(self, num_episodes=100):\n",
        "        total_rewards = 0\n",
        "        total_rewards_list=[]\n",
        "        for zz in range(num_episodes):\n",
        "            obs = self.env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "\n",
        "            while not done and total_rewards<100:\n",
        "                action, _ = self.model.predict(obs)\n",
        "                obs, reward, done, _ = self.env.step(action)\n",
        "                episode_reward += reward\n",
        "\n",
        "            total_rewards += episode_reward\n",
        "            print(episode_reward)\n",
        "            total_rewards_list.append(episode_reward)\n",
        "            print(zz)\n",
        "\n",
        "        average_reward = total_rewards / num_episodes\n",
        "        return average_reward,total_rewards_list\n",
        "\n",
        "\n",
        "class A2CAgent:\n",
        "    def __init__(self, env):\n",
        "        self.model = A2C(\"MlpPolicy\", env, verbose=1)\n",
        "        self.env=env\n",
        "\n",
        "    def train(self, total_timesteps):\n",
        "        self.model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    def calculate_expertise(self, num_episodes=100):\n",
        "        total_rewards = 0\n",
        "        total_rewards_list=[]\n",
        "        for zz in range(num_episodes):\n",
        "            obs = self.env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "\n",
        "            while not done and episode_reward<100:\n",
        "                action, _ = self.model.predict(obs)\n",
        "                obs, reward, done, _ = self.env.step(action)\n",
        "                episode_reward += reward\n",
        "\n",
        "            total_rewards += episode_reward\n",
        "            total_rewards_list.append(episode_reward)\n",
        "\n",
        "        average_reward = total_rewards / num_episodes\n",
        "        return average_reward,total_rewards_list\n",
        "all_rewards=[[],[],[]]\n",
        "for _ in range(10):\n",
        "\n",
        "  env = DummyVecEnv([lambda: PongEnvironment()])\n",
        "\n",
        "  dqn_agent = DQNAgent(env)\n",
        "  ppo_agent = PPOAgent(env)\n",
        "  a2c_agent = A2CAgent(env)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # dqn_agent.model = DQN.load('./dqn.zip')\n",
        "  # ppo_agent.model = PPO.load('./ppo.zip')\n",
        "  # a2c_agent.model = A2C.load('./a2c.zip')\n",
        "\n",
        "\n",
        "  total_timesteps = 100000\n",
        "  dqn_agent.train(total_timesteps)\n",
        "  ppo_agent.train(total_timesteps)\n",
        "  a2c_agent.train(total_timesteps)\n",
        "\n",
        "\n",
        "  dqn_a_r,dqn_r_l = dqn_agent.calculate_expertise(100)\n",
        "  ppo_a_r,ppo_r_l  = ppo_agent.calculate_expertise(100)\n",
        "  a2c_a_r,a2c_r_l   = a2c_agent.calculate_expertise(100)\n",
        "  all_rewards[0].append(dqn_r_l)\n",
        "  all_rewards[1].append(ppo_r_l)\n",
        "  all_rewards[2].append(a2c_r_l)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3jnq-TpJkij",
        "outputId": "a2025fbb-eabd-424a-c3d8-ce6fbec001f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 0\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 0\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 1\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 0\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 0\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 2\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 1\n",
            "Episode 35, Total Reward: 1\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 0\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 0\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 1\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 1\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 1\n",
            "Episode 48, Total Reward: 1\n",
            "Episode 49, Total Reward: 1\n",
            "Episode 50, Total Reward: 0\n",
            "Episode 51, Total Reward: 1\n",
            "Episode 52, Total Reward: 1\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 1\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 1\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 1\n",
            "Episode 60, Total Reward: 1\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 0\n",
            "Episode 64, Total Reward: 0\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 1\n",
            "Episode 67, Total Reward: 1\n",
            "Episode 68, Total Reward: 0\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 1\n",
            "Episode 71, Total Reward: 1\n",
            "Episode 72, Total Reward: 1\n",
            "Episode 73, Total Reward: 1\n",
            "Episode 74, Total Reward: 0\n",
            "Episode 75, Total Reward: 0\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 1\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 0\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 1\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 0\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 0\n",
            "Episode 89, Total Reward: 1\n",
            "Episode 90, Total Reward: 1\n",
            "Episode 91, Total Reward: 1\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 1\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 1\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 0\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 0\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 1\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 0\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 0\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 0\n",
            "Episode 112, Total Reward: 0\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 1\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 1\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 0\n",
            "Episode 122, Total Reward: 1\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 1\n",
            "Episode 126, Total Reward: 1\n",
            "Episode 127, Total Reward: 0\n",
            "Episode 128, Total Reward: 0\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 1\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 0\n",
            "Episode 134, Total Reward: 0\n",
            "Episode 135, Total Reward: 0\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 0\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 0\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 1\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 0\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 0\n",
            "Episode 148, Total Reward: 0\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 0\n",
            "Episode 153, Total Reward: 1\n",
            "Episode 154, Total Reward: 1\n",
            "Episode 155, Total Reward: 1\n",
            "Episode 156, Total Reward: 1\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 1\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 1\n",
            "Episode 161, Total Reward: 1\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 0\n",
            "Episode 165, Total Reward: 1\n",
            "Episode 166, Total Reward: 0\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 0\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 1\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 0\n",
            "Episode 178, Total Reward: 0\n",
            "Episode 179, Total Reward: 0\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 0\n",
            "Episode 182, Total Reward: 0\n",
            "Episode 183, Total Reward: 1\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 0\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 1\n",
            "Episode 190, Total Reward: 1\n",
            "Episode 191, Total Reward: 0\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 0\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 1\n",
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 1\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 2\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 1\n",
            "Episode 10, Total Reward: 1\n",
            "Episode 11, Total Reward: 1\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 0\n",
            "Episode 14, Total Reward: 1\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 0\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 1\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 1\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 1\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 1\n",
            "Episode 35, Total Reward: 1\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 1\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 1\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 1\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 0\n",
            "Episode 49, Total Reward: 0\n",
            "Episode 50, Total Reward: 2\n",
            "Episode 51, Total Reward: 0\n",
            "Episode 52, Total Reward: 1\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 1\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 0\n",
            "Episode 60, Total Reward: 0\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 0\n",
            "Episode 64, Total Reward: 0\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 1\n",
            "Episode 68, Total Reward: 0\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 1\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 1\n",
            "Episode 73, Total Reward: 0\n",
            "Episode 74, Total Reward: 1\n",
            "Episode 75, Total Reward: 0\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 1\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 0\n",
            "Episode 85, Total Reward: 1\n",
            "Episode 86, Total Reward: 1\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 0\n",
            "Episode 89, Total Reward: 1\n",
            "Episode 90, Total Reward: 1\n",
            "Episode 91, Total Reward: 1\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 1\n",
            "Episode 94, Total Reward: 0\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 0\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 1\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 0\n",
            "Episode 103, Total Reward: 1\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 1\n",
            "Episode 106, Total Reward: 1\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 1\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 0\n",
            "Episode 112, Total Reward: 1\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 1\n",
            "Episode 117, Total Reward: 0\n",
            "Episode 118, Total Reward: 1\n",
            "Episode 119, Total Reward: 0\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 1\n",
            "Episode 122, Total Reward: 0\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 1\n",
            "Episode 126, Total Reward: 1\n",
            "Episode 127, Total Reward: 0\n",
            "Episode 128, Total Reward: 0\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 0\n",
            "Episode 134, Total Reward: 1\n",
            "Episode 135, Total Reward: 0\n",
            "Episode 136, Total Reward: 1\n",
            "Episode 137, Total Reward: 1\n",
            "Episode 138, Total Reward: 1\n",
            "Episode 139, Total Reward: 0\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 1\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 1\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 0\n",
            "Episode 148, Total Reward: 1\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 0\n",
            "Episode 153, Total Reward: 0\n",
            "Episode 154, Total Reward: 0\n",
            "Episode 155, Total Reward: 0\n",
            "Episode 156, Total Reward: 0\n",
            "Episode 157, Total Reward: 1\n",
            "Episode 158, Total Reward: 0\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 0\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 1\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 1\n",
            "Episode 167, Total Reward: 1\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 1\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 0\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 0\n",
            "Episode 178, Total Reward: 0\n",
            "Episode 179, Total Reward: 0\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 0\n",
            "Episode 182, Total Reward: 1\n",
            "Episode 183, Total Reward: 0\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 1\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 0\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 1\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 1\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 0\n",
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 1\n",
            "Episode 7, Total Reward: 0\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 1\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 1\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 0\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 1\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 0\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 1\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 1\n",
            "Episode 41, Total Reward: 0\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 0\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 1\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 1\n",
            "Episode 48, Total Reward: 1\n",
            "Episode 49, Total Reward: 1\n",
            "Episode 50, Total Reward: 1\n",
            "Episode 51, Total Reward: 0\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 1\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 0\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 1\n",
            "Episode 60, Total Reward: 0\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 0\n",
            "Episode 64, Total Reward: 0\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 1\n",
            "Episode 67, Total Reward: 1\n",
            "Episode 68, Total Reward: 1\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 0\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 0\n",
            "Episode 73, Total Reward: 0\n",
            "Episode 74, Total Reward: 1\n",
            "Episode 75, Total Reward: 0\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 1\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 0\n",
            "Episode 81, Total Reward: 1\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 1\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 0\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 1\n",
            "Episode 89, Total Reward: 1\n",
            "Episode 90, Total Reward: 1\n",
            "Episode 91, Total Reward: 1\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 0\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 0\n",
            "Episode 98, Total Reward: 1\n",
            "Episode 99, Total Reward: 0\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 0\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 1\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 0\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 1\n",
            "Episode 112, Total Reward: 1\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 1\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 0\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 1\n",
            "Episode 122, Total Reward: 1\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 1\n",
            "Episode 127, Total Reward: 0\n",
            "Episode 128, Total Reward: 1\n",
            "Episode 129, Total Reward: 1\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 1\n",
            "Episode 134, Total Reward: 1\n",
            "Episode 135, Total Reward: 1\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 0\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 0\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 1\n",
            "Episode 143, Total Reward: 0\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 0\n",
            "Episode 146, Total Reward: 1\n",
            "Episode 147, Total Reward: 0\n",
            "Episode 148, Total Reward: 0\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 0\n",
            "Episode 152, Total Reward: 1\n",
            "Episode 153, Total Reward: 1\n",
            "Episode 154, Total Reward: 0\n",
            "Episode 155, Total Reward: 0\n",
            "Episode 156, Total Reward: 1\n",
            "Episode 157, Total Reward: 1\n",
            "Episode 158, Total Reward: 1\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 1\n",
            "Episode 161, Total Reward: 1\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 0\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 1\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 1\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 1\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 0\n",
            "Episode 178, Total Reward: 0\n",
            "Episode 179, Total Reward: 0\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 1\n",
            "Episode 182, Total Reward: 0\n",
            "Episode 183, Total Reward: 1\n",
            "Episode 184, Total Reward: 1\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 1\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 0\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 1\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 1\n",
            "Episode 195, Total Reward: 1\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 1\n",
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 0\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 1\n",
            "Episode 13, Total Reward: 1\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 1\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 1\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 1\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 0\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 1\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 0\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 1\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 0\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 0\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 1\n",
            "Episode 49, Total Reward: 0\n",
            "Episode 50, Total Reward: 0\n",
            "Episode 51, Total Reward: 0\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 1\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 0\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 0\n",
            "Episode 60, Total Reward: 1\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 1\n",
            "Episode 64, Total Reward: 1\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 0\n",
            "Episode 68, Total Reward: 1\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 0\n",
            "Episode 71, Total Reward: 1\n",
            "Episode 72, Total Reward: 1\n",
            "Episode 73, Total Reward: 1\n",
            "Episode 74, Total Reward: 0\n",
            "Episode 75, Total Reward: 1\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 1\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 0\n",
            "Episode 81, Total Reward: 1\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 0\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 0\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 1\n",
            "Episode 89, Total Reward: 1\n",
            "Episode 90, Total Reward: 1\n",
            "Episode 91, Total Reward: 1\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 0\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 1\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 0\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 1\n",
            "Episode 102, Total Reward: 0\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 1\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 1\n",
            "Episode 109, Total Reward: 1\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 0\n",
            "Episode 112, Total Reward: 1\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 1\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 0\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 1\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 0\n",
            "Episode 122, Total Reward: 0\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 1\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 0\n",
            "Episode 127, Total Reward: 1\n",
            "Episode 128, Total Reward: 0\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 1\n",
            "Episode 134, Total Reward: 0\n",
            "Episode 135, Total Reward: 1\n",
            "Episode 136, Total Reward: 1\n",
            "Episode 137, Total Reward: 1\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 1\n",
            "Episode 140, Total Reward: 1\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 1\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 0\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 1\n",
            "Episode 148, Total Reward: 1\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 1\n",
            "Episode 153, Total Reward: 1\n",
            "Episode 154, Total Reward: 1\n",
            "Episode 155, Total Reward: 0\n",
            "Episode 156, Total Reward: 0\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 0\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 0\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 1\n",
            "Episode 164, Total Reward: 1\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 0\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 1\n",
            "Episode 169, Total Reward: 1\n",
            "Episode 170, Total Reward: 1\n",
            "Episode 171, Total Reward: 1\n",
            "Episode 172, Total Reward: 0\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 0\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 1\n",
            "Episode 178, Total Reward: 1\n",
            "Episode 179, Total Reward: 1\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 0\n",
            "Episode 182, Total Reward: 0\n",
            "Episode 183, Total Reward: 0\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 0\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 1\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 1\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 1\n",
            "Episode 194, Total Reward: 0\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 1\n",
            "Episode 199, Total Reward: 1\n",
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 1\n",
            "Episode 7, Total Reward: 0\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 0\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 1\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 1\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 0\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 1\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 1\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 1\n",
            "Episode 32, Total Reward: 1\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 1\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 1\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 0\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 1\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 0\n",
            "Episode 49, Total Reward: 1\n",
            "Episode 50, Total Reward: 1\n",
            "Episode 51, Total Reward: 0\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 0\n",
            "Episode 58, Total Reward: 0\n",
            "Episode 59, Total Reward: 0\n",
            "Episode 60, Total Reward: 1\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 1\n",
            "Episode 64, Total Reward: 1\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 0\n",
            "Episode 68, Total Reward: 0\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 0\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 1\n",
            "Episode 73, Total Reward: 0\n",
            "Episode 74, Total Reward: 0\n",
            "Episode 75, Total Reward: 1\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 1\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 1\n",
            "Episode 81, Total Reward: 1\n",
            "Episode 82, Total Reward: 1\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 1\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 0\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 1\n",
            "Episode 89, Total Reward: 0\n",
            "Episode 90, Total Reward: 3\n",
            "Episode 91, Total Reward: 0\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 0\n",
            "Episode 94, Total Reward: 0\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 1\n",
            "Episode 98, Total Reward: 1\n",
            "Episode 99, Total Reward: 1\n",
            "Episode 100, Total Reward: 1\n",
            "Episode 101, Total Reward: 1\n",
            "Episode 102, Total Reward: 1\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 1\n",
            "Episode 106, Total Reward: 1\n",
            "Episode 107, Total Reward: 1\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 1\n",
            "Episode 110, Total Reward: 1\n",
            "Episode 111, Total Reward: 0\n",
            "Episode 112, Total Reward: 0\n",
            "Episode 113, Total Reward: 1\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 0\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 1\n",
            "Episode 120, Total Reward: 1\n",
            "Episode 121, Total Reward: 0\n",
            "Episode 122, Total Reward: 0\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 1\n",
            "Episode 127, Total Reward: 1\n",
            "Episode 128, Total Reward: 1\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 1\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 1\n",
            "Episode 134, Total Reward: 0\n",
            "Episode 135, Total Reward: 0\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 1\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 0\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 1\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 1\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 0\n",
            "Episode 148, Total Reward: 1\n",
            "Episode 149, Total Reward: 1\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 0\n",
            "Episode 153, Total Reward: 1\n",
            "Episode 154, Total Reward: 1\n",
            "Episode 155, Total Reward: 1\n",
            "Episode 156, Total Reward: 1\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 0\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 0\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 0\n",
            "Episode 165, Total Reward: 1\n",
            "Episode 166, Total Reward: 1\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 1\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 1\n",
            "Episode 175, Total Reward: 1\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 0\n",
            "Episode 178, Total Reward: 1\n",
            "Episode 179, Total Reward: 1\n",
            "Episode 180, Total Reward: 1\n",
            "Episode 181, Total Reward: 1\n",
            "Episode 182, Total Reward: 1\n",
            "Episode 183, Total Reward: 0\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 1\n",
            "Episode 187, Total Reward: 1\n",
            "Episode 188, Total Reward: 0\n",
            "Episode 189, Total Reward: 0\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 1\n",
            "Episode 192, Total Reward: 1\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 1\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 0\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 1\n",
            "Episode 0, Total Reward: 1\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 1\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 1\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 0\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 1\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 0\n",
            "Episode 18, Total Reward: 1\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 2\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 2\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 0\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 0\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 0\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 0\n",
            "Episode 49, Total Reward: 0\n",
            "Episode 50, Total Reward: 1\n",
            "Episode 51, Total Reward: 1\n",
            "Episode 52, Total Reward: 1\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 1\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 0\n",
            "Episode 58, Total Reward: 0\n",
            "Episode 59, Total Reward: 0\n",
            "Episode 60, Total Reward: 1\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 1\n",
            "Episode 64, Total Reward: 0\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 1\n",
            "Episode 67, Total Reward: 0\n",
            "Episode 68, Total Reward: 1\n",
            "Episode 69, Total Reward: 1\n",
            "Episode 70, Total Reward: 0\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 0\n",
            "Episode 73, Total Reward: 0\n",
            "Episode 74, Total Reward: 1\n",
            "Episode 75, Total Reward: 1\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 1\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 1\n",
            "Episode 80, Total Reward: 1\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 1\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 1\n",
            "Episode 85, Total Reward: 1\n",
            "Episode 86, Total Reward: 1\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 1\n",
            "Episode 89, Total Reward: 0\n",
            "Episode 90, Total Reward: 1\n",
            "Episode 91, Total Reward: 0\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 1\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 1\n",
            "Episode 97, Total Reward: 0\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 0\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 1\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 0\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 1\n",
            "Episode 109, Total Reward: 0\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 1\n",
            "Episode 112, Total Reward: 1\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 1\n",
            "Episode 118, Total Reward: 1\n",
            "Episode 119, Total Reward: 0\n",
            "Episode 120, Total Reward: 1\n",
            "Episode 121, Total Reward: 1\n",
            "Episode 122, Total Reward: 1\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 1\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 0\n",
            "Episode 127, Total Reward: 1\n",
            "Episode 128, Total Reward: 1\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 1\n",
            "Episode 134, Total Reward: 1\n",
            "Episode 135, Total Reward: 0\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 1\n",
            "Episode 138, Total Reward: 1\n",
            "Episode 139, Total Reward: 1\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 1\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 0\n",
            "Episode 144, Total Reward: 1\n",
            "Episode 145, Total Reward: 0\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 1\n",
            "Episode 148, Total Reward: 0\n",
            "Episode 149, Total Reward: 1\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 0\n",
            "Episode 152, Total Reward: 0\n",
            "Episode 153, Total Reward: 1\n",
            "Episode 154, Total Reward: 0\n",
            "Episode 155, Total Reward: 2\n",
            "Episode 156, Total Reward: 1\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 0\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 1\n",
            "Episode 161, Total Reward: 1\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 0\n",
            "Episode 165, Total Reward: 1\n",
            "Episode 166, Total Reward: 1\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 1\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 1\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 1\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 1\n",
            "Episode 177, Total Reward: 1\n",
            "Episode 178, Total Reward: 1\n",
            "Episode 179, Total Reward: 1\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 1\n",
            "Episode 182, Total Reward: 1\n",
            "Episode 183, Total Reward: 1\n",
            "Episode 184, Total Reward: 1\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 0\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 2\n",
            "Episode 190, Total Reward: 1\n",
            "Episode 191, Total Reward: 0\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 1\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 1\n",
            "Episode 197, Total Reward: 0\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 0\n",
            "Episode 0, Total Reward: 1\n",
            "Episode 1, Total Reward: 1\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 1\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 1\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 1\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 0\n",
            "Episode 18, Total Reward: 1\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 0\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 2\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 0\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 1\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 1\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 1\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 1\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 0\n",
            "Episode 46, Total Reward: 1\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 0\n",
            "Episode 49, Total Reward: 0\n",
            "Episode 50, Total Reward: 0\n",
            "Episode 51, Total Reward: 0\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 1\n",
            "Episode 58, Total Reward: 0\n",
            "Episode 59, Total Reward: 0\n",
            "Episode 60, Total Reward: 0\n",
            "Episode 61, Total Reward: 1\n",
            "Episode 62, Total Reward: 1\n",
            "Episode 63, Total Reward: 1\n",
            "Episode 64, Total Reward: 1\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 0\n",
            "Episode 68, Total Reward: 0\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 1\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 0\n",
            "Episode 73, Total Reward: 1\n",
            "Episode 74, Total Reward: 0\n",
            "Episode 75, Total Reward: 1\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 1\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 0\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 1\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 1\n",
            "Episode 89, Total Reward: 0\n",
            "Episode 90, Total Reward: 0\n",
            "Episode 91, Total Reward: 0\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 0\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 1\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 1\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 0\n",
            "Episode 103, Total Reward: 1\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 0\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 0\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 1\n",
            "Episode 112, Total Reward: 1\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 1\n",
            "Episode 115, Total Reward: 1\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 0\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 1\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 1\n",
            "Episode 122, Total Reward: 1\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 0\n",
            "Episode 127, Total Reward: 0\n",
            "Episode 128, Total Reward: 1\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 1\n",
            "Episode 134, Total Reward: 1\n",
            "Episode 135, Total Reward: 0\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 0\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 0\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 0\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 1\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 1\n",
            "Episode 148, Total Reward: 0\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 1\n",
            "Episode 153, Total Reward: 0\n",
            "Episode 154, Total Reward: 1\n",
            "Episode 155, Total Reward: 1\n",
            "Episode 156, Total Reward: 1\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 1\n",
            "Episode 159, Total Reward: 1\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 1\n",
            "Episode 162, Total Reward: 1\n",
            "Episode 163, Total Reward: 1\n",
            "Episode 164, Total Reward: 0\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 0\n",
            "Episode 167, Total Reward: 1\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 0\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 0\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 1\n",
            "Episode 178, Total Reward: 1\n",
            "Episode 179, Total Reward: 0\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 0\n",
            "Episode 182, Total Reward: 1\n",
            "Episode 183, Total Reward: 0\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 1\n",
            "Episode 187, Total Reward: 0\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 0\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 1\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 0\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 0\n",
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 1\n",
            "Episode 3, Total Reward: 1\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 0\n",
            "Episode 8, Total Reward: 1\n",
            "Episode 9, Total Reward: 1\n",
            "Episode 10, Total Reward: 1\n",
            "Episode 11, Total Reward: 1\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 0\n",
            "Episode 14, Total Reward: 1\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 1\n",
            "Episode 17, Total Reward: 0\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 1\n",
            "Episode 20, Total Reward: 1\n",
            "Episode 21, Total Reward: 0\n",
            "Episode 22, Total Reward: 1\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 1\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 0\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 0\n",
            "Episode 41, Total Reward: 0\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 0\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 0\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 1\n",
            "Episode 49, Total Reward: 0\n",
            "Episode 50, Total Reward: 0\n",
            "Episode 51, Total Reward: 0\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 0\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 0\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 0\n",
            "Episode 60, Total Reward: 0\n",
            "Episode 61, Total Reward: 0\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 0\n",
            "Episode 64, Total Reward: 0\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 1\n",
            "Episode 68, Total Reward: 1\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 0\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 0\n",
            "Episode 73, Total Reward: 0\n",
            "Episode 74, Total Reward: 2\n",
            "Episode 75, Total Reward: 0\n",
            "Episode 76, Total Reward: 1\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 0\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 0\n",
            "Episode 85, Total Reward: 1\n",
            "Episode 86, Total Reward: 0\n",
            "Episode 87, Total Reward: 0\n",
            "Episode 88, Total Reward: 2\n",
            "Episode 89, Total Reward: 0\n",
            "Episode 90, Total Reward: 0\n",
            "Episode 91, Total Reward: 0\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 0\n",
            "Episode 94, Total Reward: 0\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 0\n",
            "Episode 97, Total Reward: 0\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 0\n",
            "Episode 100, Total Reward: 1\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 0\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 0\n",
            "Episode 105, Total Reward: 0\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 1\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 1\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 0\n",
            "Episode 112, Total Reward: 0\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 1\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 1\n",
            "Episode 117, Total Reward: 1\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 0\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 0\n",
            "Episode 122, Total Reward: 1\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 0\n",
            "Episode 127, Total Reward: 1\n",
            "Episode 128, Total Reward: 1\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 1\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 0\n",
            "Episode 134, Total Reward: 0\n",
            "Episode 135, Total Reward: 1\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 1\n",
            "Episode 138, Total Reward: 1\n",
            "Episode 139, Total Reward: 0\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 1\n",
            "Episode 143, Total Reward: 0\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 0\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 1\n",
            "Episode 148, Total Reward: 0\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 1\n",
            "Episode 153, Total Reward: 0\n",
            "Episode 154, Total Reward: 0\n",
            "Episode 155, Total Reward: 0\n",
            "Episode 156, Total Reward: 0\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 1\n",
            "Episode 159, Total Reward: 1\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 0\n",
            "Episode 162, Total Reward: 1\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 1\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 0\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 0\n",
            "Episode 169, Total Reward: 1\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 0\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 0\n",
            "Episode 175, Total Reward: 1\n",
            "Episode 176, Total Reward: 1\n",
            "Episode 177, Total Reward: 0\n",
            "Episode 178, Total Reward: 0\n",
            "Episode 179, Total Reward: 1\n",
            "Episode 180, Total Reward: 0\n",
            "Episode 181, Total Reward: 1\n",
            "Episode 182, Total Reward: 0\n",
            "Episode 183, Total Reward: 0\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 1\n",
            "Episode 188, Total Reward: 0\n",
            "Episode 189, Total Reward: 1\n",
            "Episode 190, Total Reward: 1\n",
            "Episode 191, Total Reward: 0\n",
            "Episode 192, Total Reward: 0\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 1\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 0\n",
            "Episode 198, Total Reward: 1\n",
            "Episode 199, Total Reward: 0\n",
            "Episode 0, Total Reward: 0\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 0\n",
            "Episode 5, Total Reward: 0\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 1\n",
            "Episode 8, Total Reward: 1\n",
            "Episode 9, Total Reward: 0\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 0\n",
            "Episode 13, Total Reward: 1\n",
            "Episode 14, Total Reward: 0\n",
            "Episode 15, Total Reward: 0\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 0\n",
            "Episode 18, Total Reward: 1\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 1\n",
            "Episode 21, Total Reward: 0\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 0\n",
            "Episode 24, Total Reward: 1\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 0\n",
            "Episode 28, Total Reward: 0\n",
            "Episode 29, Total Reward: 0\n",
            "Episode 30, Total Reward: 1\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 1\n",
            "Episode 33, Total Reward: 1\n",
            "Episode 34, Total Reward: 1\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 1\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 0\n",
            "Episode 40, Total Reward: 1\n",
            "Episode 41, Total Reward: 1\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 0\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 0\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 1\n",
            "Episode 48, Total Reward: 0\n",
            "Episode 49, Total Reward: 0\n",
            "Episode 50, Total Reward: 0\n",
            "Episode 51, Total Reward: 1\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 1\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 1\n",
            "Episode 57, Total Reward: 0\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 1\n",
            "Episode 60, Total Reward: 0\n",
            "Episode 61, Total Reward: 1\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 0\n",
            "Episode 64, Total Reward: 1\n",
            "Episode 65, Total Reward: 0\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 0\n",
            "Episode 68, Total Reward: 0\n",
            "Episode 69, Total Reward: 0\n",
            "Episode 70, Total Reward: 1\n",
            "Episode 71, Total Reward: 0\n",
            "Episode 72, Total Reward: 0\n",
            "Episode 73, Total Reward: 1\n",
            "Episode 74, Total Reward: 0\n",
            "Episode 75, Total Reward: 1\n",
            "Episode 76, Total Reward: 1\n",
            "Episode 77, Total Reward: 0\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 1\n",
            "Episode 80, Total Reward: 0\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 1\n",
            "Episode 83, Total Reward: 1\n",
            "Episode 84, Total Reward: 0\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 0\n",
            "Episode 87, Total Reward: 1\n",
            "Episode 88, Total Reward: 0\n",
            "Episode 89, Total Reward: 0\n",
            "Episode 90, Total Reward: 0\n",
            "Episode 91, Total Reward: 0\n",
            "Episode 92, Total Reward: 0\n",
            "Episode 93, Total Reward: 1\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 1\n",
            "Episode 97, Total Reward: 0\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 0\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 0\n",
            "Episode 102, Total Reward: 1\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 1\n",
            "Episode 105, Total Reward: 1\n",
            "Episode 106, Total Reward: 1\n",
            "Episode 107, Total Reward: 1\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 1\n",
            "Episode 110, Total Reward: 0\n",
            "Episode 111, Total Reward: 1\n",
            "Episode 112, Total Reward: 0\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 1\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 0\n",
            "Episode 118, Total Reward: 1\n",
            "Episode 119, Total Reward: 0\n",
            "Episode 120, Total Reward: 1\n",
            "Episode 121, Total Reward: 0\n",
            "Episode 122, Total Reward: 0\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 1\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 0\n",
            "Episode 127, Total Reward: 0\n",
            "Episode 128, Total Reward: 0\n",
            "Episode 129, Total Reward: 0\n",
            "Episode 130, Total Reward: 1\n",
            "Episode 131, Total Reward: 1\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 0\n",
            "Episode 134, Total Reward: 0\n",
            "Episode 135, Total Reward: 0\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 1\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 1\n",
            "Episode 140, Total Reward: 1\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 1\n",
            "Episode 143, Total Reward: 0\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 0\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 0\n",
            "Episode 148, Total Reward: 1\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 1\n",
            "Episode 151, Total Reward: 0\n",
            "Episode 152, Total Reward: 0\n",
            "Episode 153, Total Reward: 1\n",
            "Episode 154, Total Reward: 0\n",
            "Episode 155, Total Reward: 0\n",
            "Episode 156, Total Reward: 0\n",
            "Episode 157, Total Reward: 0\n",
            "Episode 158, Total Reward: 0\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 0\n",
            "Episode 162, Total Reward: 1\n",
            "Episode 163, Total Reward: 0\n",
            "Episode 164, Total Reward: 1\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 0\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 1\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 1\n",
            "Episode 172, Total Reward: 0\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 0\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 1\n",
            "Episode 178, Total Reward: 0\n",
            "Episode 179, Total Reward: 0\n",
            "Episode 180, Total Reward: 1\n",
            "Episode 181, Total Reward: 1\n",
            "Episode 182, Total Reward: 1\n",
            "Episode 183, Total Reward: 1\n",
            "Episode 184, Total Reward: 1\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 0\n",
            "Episode 188, Total Reward: 0\n",
            "Episode 189, Total Reward: 0\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 1\n",
            "Episode 192, Total Reward: 1\n",
            "Episode 193, Total Reward: 1\n",
            "Episode 194, Total Reward: 0\n",
            "Episode 195, Total Reward: 1\n",
            "Episode 196, Total Reward: 1\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 1\n",
            "Episode 199, Total Reward: 1\n",
            "Episode 0, Total Reward: 1\n",
            "Episode 1, Total Reward: 0\n",
            "Episode 2, Total Reward: 0\n",
            "Episode 3, Total Reward: 0\n",
            "Episode 4, Total Reward: 1\n",
            "Episode 5, Total Reward: 1\n",
            "Episode 6, Total Reward: 0\n",
            "Episode 7, Total Reward: 1\n",
            "Episode 8, Total Reward: 0\n",
            "Episode 9, Total Reward: 1\n",
            "Episode 10, Total Reward: 0\n",
            "Episode 11, Total Reward: 0\n",
            "Episode 12, Total Reward: 1\n",
            "Episode 13, Total Reward: 0\n",
            "Episode 14, Total Reward: 1\n",
            "Episode 15, Total Reward: 1\n",
            "Episode 16, Total Reward: 0\n",
            "Episode 17, Total Reward: 1\n",
            "Episode 18, Total Reward: 0\n",
            "Episode 19, Total Reward: 0\n",
            "Episode 20, Total Reward: 0\n",
            "Episode 21, Total Reward: 1\n",
            "Episode 22, Total Reward: 0\n",
            "Episode 23, Total Reward: 1\n",
            "Episode 24, Total Reward: 0\n",
            "Episode 25, Total Reward: 0\n",
            "Episode 26, Total Reward: 1\n",
            "Episode 27, Total Reward: 1\n",
            "Episode 28, Total Reward: 1\n",
            "Episode 29, Total Reward: 1\n",
            "Episode 30, Total Reward: 0\n",
            "Episode 31, Total Reward: 0\n",
            "Episode 32, Total Reward: 0\n",
            "Episode 33, Total Reward: 0\n",
            "Episode 34, Total Reward: 0\n",
            "Episode 35, Total Reward: 0\n",
            "Episode 36, Total Reward: 0\n",
            "Episode 37, Total Reward: 1\n",
            "Episode 38, Total Reward: 1\n",
            "Episode 39, Total Reward: 1\n",
            "Episode 40, Total Reward: 1\n",
            "Episode 41, Total Reward: 0\n",
            "Episode 42, Total Reward: 0\n",
            "Episode 43, Total Reward: 1\n",
            "Episode 44, Total Reward: 0\n",
            "Episode 45, Total Reward: 0\n",
            "Episode 46, Total Reward: 0\n",
            "Episode 47, Total Reward: 0\n",
            "Episode 48, Total Reward: 0\n",
            "Episode 49, Total Reward: 1\n",
            "Episode 50, Total Reward: 0\n",
            "Episode 51, Total Reward: 1\n",
            "Episode 52, Total Reward: 0\n",
            "Episode 53, Total Reward: 0\n",
            "Episode 54, Total Reward: 1\n",
            "Episode 55, Total Reward: 0\n",
            "Episode 56, Total Reward: 0\n",
            "Episode 57, Total Reward: 1\n",
            "Episode 58, Total Reward: 1\n",
            "Episode 59, Total Reward: 1\n",
            "Episode 60, Total Reward: 0\n",
            "Episode 61, Total Reward: 1\n",
            "Episode 62, Total Reward: 0\n",
            "Episode 63, Total Reward: 0\n",
            "Episode 64, Total Reward: 1\n",
            "Episode 65, Total Reward: 1\n",
            "Episode 66, Total Reward: 0\n",
            "Episode 67, Total Reward: 5\n",
            "Episode 68, Total Reward: 0\n",
            "Episode 69, Total Reward: 1\n",
            "Episode 70, Total Reward: 1\n",
            "Episode 71, Total Reward: 1\n",
            "Episode 72, Total Reward: 0\n",
            "Episode 73, Total Reward: 1\n",
            "Episode 74, Total Reward: 0\n",
            "Episode 75, Total Reward: 0\n",
            "Episode 76, Total Reward: 0\n",
            "Episode 77, Total Reward: 1\n",
            "Episode 78, Total Reward: 0\n",
            "Episode 79, Total Reward: 0\n",
            "Episode 80, Total Reward: 0\n",
            "Episode 81, Total Reward: 0\n",
            "Episode 82, Total Reward: 0\n",
            "Episode 83, Total Reward: 0\n",
            "Episode 84, Total Reward: 1\n",
            "Episode 85, Total Reward: 0\n",
            "Episode 86, Total Reward: 1\n",
            "Episode 87, Total Reward: 1\n",
            "Episode 88, Total Reward: 0\n",
            "Episode 89, Total Reward: 0\n",
            "Episode 90, Total Reward: 1\n",
            "Episode 91, Total Reward: 0\n",
            "Episode 92, Total Reward: 1\n",
            "Episode 93, Total Reward: 1\n",
            "Episode 94, Total Reward: 1\n",
            "Episode 95, Total Reward: 0\n",
            "Episode 96, Total Reward: 1\n",
            "Episode 97, Total Reward: 1\n",
            "Episode 98, Total Reward: 0\n",
            "Episode 99, Total Reward: 1\n",
            "Episode 100, Total Reward: 0\n",
            "Episode 101, Total Reward: 1\n",
            "Episode 102, Total Reward: 0\n",
            "Episode 103, Total Reward: 0\n",
            "Episode 104, Total Reward: 1\n",
            "Episode 105, Total Reward: 0\n",
            "Episode 106, Total Reward: 0\n",
            "Episode 107, Total Reward: 0\n",
            "Episode 108, Total Reward: 0\n",
            "Episode 109, Total Reward: 1\n",
            "Episode 110, Total Reward: 1\n",
            "Episode 111, Total Reward: 0\n",
            "Episode 112, Total Reward: 0\n",
            "Episode 113, Total Reward: 0\n",
            "Episode 114, Total Reward: 0\n",
            "Episode 115, Total Reward: 0\n",
            "Episode 116, Total Reward: 0\n",
            "Episode 117, Total Reward: 0\n",
            "Episode 118, Total Reward: 0\n",
            "Episode 119, Total Reward: 0\n",
            "Episode 120, Total Reward: 0\n",
            "Episode 121, Total Reward: 0\n",
            "Episode 122, Total Reward: 0\n",
            "Episode 123, Total Reward: 0\n",
            "Episode 124, Total Reward: 0\n",
            "Episode 125, Total Reward: 0\n",
            "Episode 126, Total Reward: 1\n",
            "Episode 127, Total Reward: 0\n",
            "Episode 128, Total Reward: 1\n",
            "Episode 129, Total Reward: 1\n",
            "Episode 130, Total Reward: 0\n",
            "Episode 131, Total Reward: 0\n",
            "Episode 132, Total Reward: 0\n",
            "Episode 133, Total Reward: 0\n",
            "Episode 134, Total Reward: 1\n",
            "Episode 135, Total Reward: 1\n",
            "Episode 136, Total Reward: 0\n",
            "Episode 137, Total Reward: 0\n",
            "Episode 138, Total Reward: 0\n",
            "Episode 139, Total Reward: 1\n",
            "Episode 140, Total Reward: 0\n",
            "Episode 141, Total Reward: 0\n",
            "Episode 142, Total Reward: 0\n",
            "Episode 143, Total Reward: 1\n",
            "Episode 144, Total Reward: 0\n",
            "Episode 145, Total Reward: 1\n",
            "Episode 146, Total Reward: 0\n",
            "Episode 147, Total Reward: 0\n",
            "Episode 148, Total Reward: 0\n",
            "Episode 149, Total Reward: 0\n",
            "Episode 150, Total Reward: 0\n",
            "Episode 151, Total Reward: 1\n",
            "Episode 152, Total Reward: 0\n",
            "Episode 153, Total Reward: 0\n",
            "Episode 154, Total Reward: 1\n",
            "Episode 155, Total Reward: 0\n",
            "Episode 156, Total Reward: 1\n",
            "Episode 157, Total Reward: 1\n",
            "Episode 158, Total Reward: 0\n",
            "Episode 159, Total Reward: 0\n",
            "Episode 160, Total Reward: 0\n",
            "Episode 161, Total Reward: 1\n",
            "Episode 162, Total Reward: 0\n",
            "Episode 163, Total Reward: 1\n",
            "Episode 164, Total Reward: 0\n",
            "Episode 165, Total Reward: 0\n",
            "Episode 166, Total Reward: 1\n",
            "Episode 167, Total Reward: 0\n",
            "Episode 168, Total Reward: 1\n",
            "Episode 169, Total Reward: 0\n",
            "Episode 170, Total Reward: 0\n",
            "Episode 171, Total Reward: 0\n",
            "Episode 172, Total Reward: 0\n",
            "Episode 173, Total Reward: 0\n",
            "Episode 174, Total Reward: 0\n",
            "Episode 175, Total Reward: 0\n",
            "Episode 176, Total Reward: 0\n",
            "Episode 177, Total Reward: 0\n",
            "Episode 178, Total Reward: 1\n",
            "Episode 179, Total Reward: 0\n",
            "Episode 180, Total Reward: 1\n",
            "Episode 181, Total Reward: 1\n",
            "Episode 182, Total Reward: 0\n",
            "Episode 183, Total Reward: 1\n",
            "Episode 184, Total Reward: 0\n",
            "Episode 185, Total Reward: 0\n",
            "Episode 186, Total Reward: 0\n",
            "Episode 187, Total Reward: 0\n",
            "Episode 188, Total Reward: 1\n",
            "Episode 189, Total Reward: 1\n",
            "Episode 190, Total Reward: 0\n",
            "Episode 191, Total Reward: 0\n",
            "Episode 192, Total Reward: 1\n",
            "Episode 193, Total Reward: 0\n",
            "Episode 194, Total Reward: 0\n",
            "Episode 195, Total Reward: 0\n",
            "Episode 196, Total Reward: 0\n",
            "Episode 197, Total Reward: 1\n",
            "Episode 198, Total Reward: 0\n",
            "Episode 199, Total Reward: 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pygame\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))  # Convert states to numpy arrays for storage\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        # for b in batch:\n",
        "        #     print(b)\n",
        "        #     print(f'{(list(b[0]))}')\n",
        "        #     print(f'-{(list(b[1]))}')\n",
        "        #     print(f'-{(list(b[2]))}')\n",
        "        #     print(f'-{(list(b[3]))}')\n",
        "        #     print(f'-{(b[4])}-')\n",
        "        #     print(len(b[1]))\n",
        "        #     print(len(b[2]))\n",
        "        #     print(len(b[3]))\n",
        "        #     # print(len(b[4]))\n",
        "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
        "\n",
        "        return torch.FloatTensor(state), torch.LongTensor(action), torch.FloatTensor(reward), torch.FloatTensor(next_state), torch.FloatTensor(done)\n",
        "\n",
        "\n",
        "class PongEnvironment:\n",
        "    def __init__(self, width=400, height=300):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.ball_radius = 10\n",
        "        self.paddle_width = 10\n",
        "        self.paddle_height = 60\n",
        "        self.paddle_offset = 20\n",
        "        self.ball_pos = np.array(\n",
        "            [self.width // 2, random.randint(0, self.height) // 2], dtype=float\n",
        "        )\n",
        "        self.ball_vel = np.array([0.03, 0.01], dtype=float) * 100\n",
        "        self.paddle_pos = random.randint(0, self.height)\n",
        "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
        "        pygame.display.set_caption(\"Pong\")\n",
        "\n",
        "    def reset(self):\n",
        "        self.start_time = time.time()\n",
        "        self.total_reward = 0\n",
        "        self.ball_pos = np.array(\n",
        "            [self.width // 2, random.randint(0, self.height)], dtype=float\n",
        "        )\n",
        "        self.ball_vel = np.array([0.03, 0.01], dtype=float) * 100\n",
        "        self.paddle_pos = random.randint(0, self.height)\n",
        "        return torch.FloatTensor(self.get_state())\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            move = -5\n",
        "        else:\n",
        "            move = 5\n",
        "        self.move_paddle(move)\n",
        "        self.ball_pos += self.ball_vel\n",
        "\n",
        "        if (\n",
        "            self.ball_pos[1] <= self.ball_radius\n",
        "            or self.ball_pos[1] >= self.height - self.ball_radius\n",
        "        ):\n",
        "            self.ball_vel[1] *= -1\n",
        "\n",
        "        reward = 0\n",
        "        done = False\n",
        "\n",
        "        if self.ball_pos[0] <= self.paddle_width + self.ball_radius:\n",
        "            if (\n",
        "                self.paddle_pos - self.paddle_height / 2\n",
        "                <= self.ball_pos[1]\n",
        "                <= self.paddle_pos + self.paddle_height / 2\n",
        "            ):\n",
        "                self.ball_vel[0] *= -1\n",
        "                reward = 1\n",
        "                self.total_reward += 1\n",
        "            else:\n",
        "                reward = 0\n",
        "                done = True\n",
        "        if self.total_reward > 10 or time.time() - self.start_time > 10:\n",
        "            done = True\n",
        "        if self.ball_pos[0] >= self.width - self.ball_radius - self.paddle_width:\n",
        "            self.ball_vel[0] *= -1\n",
        "\n",
        "        return torch.FloatTensor(self.get_state()), reward, done\n",
        "\n",
        "    def move_paddle(self, move):\n",
        "        self.paddle_pos = np.clip(\n",
        "            self.paddle_pos + move,\n",
        "            self.paddle_height / 2,\n",
        "            self.height - self.paddle_height / 2,\n",
        "        )\n",
        "\n",
        "    def get_state(self):\n",
        "        return np.array(\n",
        "            [\n",
        "                self.ball_pos[0] / self.width,\n",
        "                self.ball_pos[1] / self.height,\n",
        "                self.ball_vel[0] / 100,\n",
        "                self.ball_vel[1] / 100,\n",
        "                self.paddle_pos / self.height,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        self.screen.fill((0, 0, 0))\n",
        "        pygame.draw.rect(\n",
        "            self.screen,\n",
        "            (255, 255, 255),\n",
        "            pygame.Rect(\n",
        "                0,\n",
        "                int(self.paddle_pos - self.paddle_height / 2),\n",
        "                self.paddle_width,\n",
        "                self.paddle_height,\n",
        "            ),\n",
        "        )\n",
        "        pygame.draw.circle(\n",
        "            self.screen,\n",
        "            (255, 255, 255),\n",
        "            (int(self.ball_pos[0]), int(self.ball_pos[1])),\n",
        "            self.ball_radius,\n",
        "        )\n",
        "        pygame.display.flip()\n",
        "\n",
        "class PPO(nn.Module):\n",
        "    def __init__(self, state_size, action_size, hidden_size=64):\n",
        "        super(PPO, self).__init__()\n",
        "        self.p = nn.Sequential(\n",
        "            nn.Linear(state_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, action_size),\n",
        "            nn.Softmax(dim=-1),\n",
        "        )\n",
        "        self.v = nn.Sequential(\n",
        "            nn.Linear(state_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        action_probs = self.p(state)\n",
        "        value = self.v(state)\n",
        "        return action_probs, value\n",
        "\n",
        "\n",
        "\n",
        "batch_size=256\n",
        "def train_ppo(env, policy, optimizer, replay_buffer, clip_epsilon=0.2, epochs=10, batch_size=64):\n",
        "    all_rewards=[]\n",
        "    for episode in range(200):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "            action_probs, _ = policy(state_tensor)\n",
        "            action_dist = torch.distributions.Categorical(action_probs)\n",
        "            action = action_dist.sample()\n",
        "            next_state, reward, done = env.step(action.item())\n",
        "\n",
        "            # Add the agent's experience to the replay buffer\n",
        "            replay_buffer.add(state, action, reward, next_state, done)\n",
        "\n",
        "            state = next_state if not done else env.reset()\n",
        "            total_reward += reward\n",
        "\n",
        "        if len(replay_buffer.buffer) > batch_size:\n",
        "            # Sample a batch of experiences from the replay buffer\n",
        "            states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
        "\n",
        "            # Convert lists to tensors\n",
        "            states = torch.FloatTensor(states)\n",
        "            actions = torch.LongTensor(actions).view(-1, 1)\n",
        "            rewards = torch.FloatTensor(rewards).view(-1, 1)\n",
        "            dones = torch.FloatTensor(dones).view(-1, 1)\n",
        "            next_states = torch.FloatTensor(next_states)\n",
        "\n",
        "            # Compute advantages and returns\n",
        "            _, values = policy(states)\n",
        "            _, next_values = policy(next_states)\n",
        "            returns = rewards + 0.99 * next_values * (1 - dones)\n",
        "            advantages = returns - values.detach()\n",
        "\n",
        "            # Compute policy loss\n",
        "            action_probs, _ = policy(states)\n",
        "            action_dist = torch.distributions.Categorical(action_probs)\n",
        "            log_probs = action_dist.log_prob(actions.squeeze(-1)).view(-1, 1)\n",
        "            old_action_probs = action_dist.probs.detach()\n",
        "            ratios = torch.exp(log_probs - torch.log(old_action_probs))\n",
        "            obj = ratios * advantages\n",
        "            obj_clipped = ratios.clamp(1.0 - clip_epsilon, 1.0 + clip_epsilon) * advantages\n",
        "            actor_loss = -torch.min(obj, obj_clipped).mean()\n",
        "\n",
        "            # Compute value function loss\n",
        "            critic_loss = F.smooth_l1_loss(values, returns.detach())\n",
        "\n",
        "            # Total loss\n",
        "            loss = actor_loss + 0.5 * critic_loss\n",
        "\n",
        "            # Optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        all_rewards.append(total_reward)\n",
        "\n",
        "        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "    return all_rewards\n",
        "\n",
        "import torch\n",
        "\n",
        "rs=[]\n",
        "for _ in range(10):\n",
        "    env = PongEnvironment()\n",
        "    env2 = PongEnvironment()\n",
        "    replay_buffer = ReplayBuffer(capacity=100_000)\n",
        "\n",
        "    # Define state and action sizes\n",
        "    state_size = env.get_state().shape[0]\n",
        "    action_size = 2  # up and down\n",
        "\n",
        "    # Define hidden size\n",
        "    hidden_size = 64\n",
        "\n",
        "    # Initialize policy (ActorCritic network)\n",
        "    policy = PPO(state_size, action_size, hidden_size)\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = torch.optim.Adam(policy.parameters(), lr=0.001)\n",
        "\n",
        "    # Train policy with PPO\n",
        "    alls_ppo=train_ppo(env, policy, optimizer,replay_buffer)\n",
        "    rs.append(alls_ppo)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Hs174vMJkij",
        "outputId": "85c28456-6c7c-4ab4-a122-50d6d72a9b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "[ 0.01596902 -0.00556653  0.0719719   0.06491632  0.06305516  0.06295564\n",
            "  0.09374747  0.12549453  0.13377292  0.13193306  0.1259484   0.11830213\n",
            "  0.12415929  0.15660835  0.15077873  0.15048053  0.14273663  0.16254927\n",
            "  0.17036356  0.17727667  0.17423693  0.1841505   0.17617299  0.18102989\n",
            "  0.18541691  0.18938702  0.20280012  0.19561796  0.19083525  0.18689054\n",
            "  0.19772382  0.19756344  0.19820001  0.20051216  0.20423073  0.20823292\n",
            "  0.20533363  0.20148708  0.21572889  0.21006757  0.20971725  0.21635515\n",
            "  0.21132363  0.21363105  0.20888369  0.21493296  0.21214716  0.21573128\n",
            "  0.22315357  0.22655504  0.23085205  0.23322445  0.23462206  0.23253705\n",
            "  0.23134319  0.23352832  0.23031002  0.23074306  0.23723412  0.2376\n",
            "  0.24330275  0.24166834  0.23970114  0.24496502  0.24767735  0.24331517\n",
            "  0.24551173  0.24452777  0.24911519  0.24640653  0.24727107  0.24685008\n",
            "  0.25003362  0.25179259  0.25655522  0.26145842  0.26063117  0.26006527\n",
            "  0.26174137  0.26074569  0.26315985  0.26531247  0.26572326  0.26316984\n",
            "  0.26497372  0.26573309  0.26542132  0.26242703  0.27005817  0.27272881\n",
            "  0.27945239  0.2816406   0.27794094  0.27803481  0.28187979  0.27999058\n",
            "  0.27809889  0.27898478  0.27866017  0.27859832  0.27858049  0.27768952\n",
            "  0.27863978  0.2781367   0.27565328  0.27809034  0.27762481  0.27799385\n",
            "  0.27775924  0.27961248  0.27728658  0.27884002  0.28174012  0.27989573\n",
            "  0.28026546  0.28078239  0.28054508  0.28289223  0.2823324   0.28423048\n",
            "  0.28359435  0.28488939  0.28811992  0.28579637  0.28573935  0.28516901\n",
            "  0.28599332  0.28757045  0.28976364  0.28831389  0.28707581  0.28775148\n",
            "  0.28558793  0.28774636  0.28848237  0.28956826  0.28919492  0.29147512\n",
            "  0.2915747   0.29118457  0.29053787  0.28884804  0.28934969  0.29031539\n",
            "  0.28866067  0.28857995  0.28754044  0.2891023   0.28940932  0.28822075\n",
            "  0.28669307  0.28974947  0.29179124  0.29388881  0.29514385  0.29623558\n",
            "  0.29771841  0.29716499  0.29929687  0.29948307  0.29970593  0.3005106\n",
            "  0.30116449  0.30079767  0.30205303  0.30180512  0.30177056  0.30128766\n",
            "  0.30067802  0.3009974   0.29997749  0.29939623  0.29955939  0.29783778\n",
            "  0.29835857  0.2980618   0.29752875  0.29789671  0.29795772  0.29826205\n",
            "  0.29733956  0.2981954   0.29867308  0.29926547  0.29880848  0.29720198\n",
            "  0.29659231  0.29750174  0.29964159  0.3006348   0.30085216  0.30268172\n",
            "  0.30181352  0.30128871  0.30214566  0.30163964  0.30044708  0.30284947\n",
            "  0.3031523   0.30429484]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.01596902 -0.08594193  0.01596902 -0.08594193 -0.08594193  0.01596902\n",
            " -0.04792257  0.08422121 -0.04792257  0.01596902 -0.04792257 -0.04792257\n",
            " -0.04792257  0.19009679  0.01596902 -0.04792257 -0.08594193  0.09635811\n",
            "  0.01596902  0.01596902 -0.04792257  0.08422121 -0.08594193  0.01596902\n",
            " -0.09686975 -0.04792257  0.41596902 -0.08594193 -0.04792257 -0.04792257\n",
            " -0.09686975 -0.04792257 -0.04792257  0.01596902  0.01596902  0.01596902\n",
            " -0.08594193 -0.04792257  0.56622403 -0.08594193  0.01596902  0.19009679\n",
            "  0.          0.09635811  0.          0.09635811 -0.08594193  0.01596902\n",
            "  0.09635811  0.09635811  0.08422121  0.09635811  0.01596902 -0.08594193\n",
            "  0.01596902 -0.04792257 -0.08594193  0.09635811  0.41596902  0.09635811\n",
            "  0.09635811  0.01596902 -0.08594193  0.09635811  0.19009679 -0.08594193\n",
            "  0.01596902  0.00395625  0.09635811 -0.04792257  0.19009679  0.01596902\n",
            "  0.09635811  0.19009679  0.08422121  0.19009679 -0.04792257  0.01596902\n",
            "  0.01596902 -0.04792257  0.09635811  0.01596902  0.01596902 -0.08594193\n",
            "  0.19009679  0.01596902  0.09635811 -0.04792257  0.30313025  0.09635811\n",
            "  0.38515012  0.09635811 -0.08594193  0.19009679  0.41596902 -0.08594193\n",
            "  0.01596902  0.09635811 -0.04792257  0.09635811 -0.04792257  0.01596902\n",
            "  0.09635811 -0.04792257 -0.04792257  0.19009679  0.01596902  0.01596902\n",
            " -0.04792257  0.29635811 -0.04792257  0.09635811  0.19009679 -0.08594193\n",
            " -0.04792257  0.01596902 -0.04792257  0.09635811  0.01596902  0.09635811\n",
            "  0.01596902  0.09635811  0.19009679  0.          0.01596902 -0.04792257\n",
            "  0.19009679  0.09635811  0.29635811 -0.04792257 -0.04792257  0.01596902\n",
            "  0.          0.19009679  0.19009679  0.09635811 -0.04792257  0.29635811\n",
            "  0.01596902  0.09635811 -0.04792257 -0.08594193  0.01596902  0.19009679\n",
            " -0.08594193  0.09635811 -0.08594193  0.09635811  0.09635811 -0.04792257\n",
            " -0.08594193  0.41596902  0.09635811  0.29635811  0.19009679  0.08422121\n",
            "  0.29635811  0.01596902  0.09635811 -0.04792257  0.01596902  0.19009679\n",
            "  0.01596902  0.01596902  0.09635811  0.01596902  0.19009679 -0.04792257\n",
            "  0.01596902  0.01596902 -0.08594193 -0.04792257  0.09635811  0.\n",
            "  0.09635811 -0.04792257 -0.04792257  0.09635811  0.19009679  0.09635811\n",
            "  0.01596902  0.29635811  0.19009679  0.19009679  0.01596902  0.\n",
            " -0.04792257  0.09635811  0.41596902  0.18886693  0.01596902  0.29635811\n",
            "  0.01596902 -0.04792257  0.19009679 -0.04792257 -0.04792257  0.41596902\n",
            "  0.01596902  0.19009679]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "alls_3=[]\n",
        "for alls_1 in rs:\n",
        "    t=0\n",
        "    list_1=[]\n",
        "    for i in range(200):\n",
        "        t+=alls_1[i]\n",
        "        list_1.append(t/(i+1))\n",
        "    alls_3.append(list_1)\n",
        "    rewards=alls_3\n",
        "mean_regret = np.mean(rewards, axis=0)\n",
        "std_regret = np.std(rewards, axis=0)\n",
        "\n",
        "upper_bound = (mean_regret + 1.96 * std_regret / np.sqrt(len(rewards))).flatten()\n",
        "lower_bound = (mean_regret - 1.96 * std_regret / np.sqrt(len(rewards))).flatten()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(mean_regret, label=\"PPO\")\n",
        "ax.fill_between(np.arange(len(mean_regret)).flatten(), lower_bound ,upper_bound , alpha=0.5)\n",
        "ax.set_title(\"Average  hit count\")\n",
        "# ax.plot(np.mean(rs, axis=0))\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "mean_regret = np.mean(rs, axis=0)\n",
        "std_regret = np.std(rs, axis=0)\n",
        "\n",
        "upper_bound = (mean_regret + 1.96 * std_regret / np.sqrt(len(rewards))).flatten()\n",
        "lower_bound = (mean_regret - 1.96 * std_regret / np.sqrt(len(rewards))).flatten()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(mean_regret, label=\"PPO\")\n",
        "ax.fill_between(np.arange(len(mean_regret)).flatten(), lower_bound ,upper_bound , alpha=0.5)\n",
        "ax.set_title(\"Mean Reward\")\n",
        "# ax.plot(np.mean(rs, axis=0))\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# plt.legend()\n",
        "# # Show the plot\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
